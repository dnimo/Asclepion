# Agents模组配置示例
# 复制此文件为 .env 并修改相应配置

# ===== LLM服务配置 =====
# OpenAI API配置
OPENAI_API_KEY=sk-your-openai-api-key-here
# Anthropic API配置  
ANTHROPIC_API_KEY=your-anthropic-api-key-here

# ===== 智能体系统配置 =====
# LLM提供者选择: openai, anthropic, local, mock
HOSPITAL_LLM_PROVIDER=mock

# LLM预设配置: openai_gpt4, openai_gpt35, anthropic_claude, local_llama, mock
HOSPITAL_LLM_PRESET=mock

# 是否启用LLM生成: true, false
HOSPITAL_ENABLE_LLM=true

# API失败时是否回退到Mock模式: true, false
HOSPITAL_FALLBACK_MOCK=true

# ===== 智能体行为配置 =====
# 默认学习率
HOSPITAL_AGENT_LEARNING_RATE=0.001

# 收益函数权重 (总和应为1.0)
HOSPITAL_ALPHA=0.3  # 全局效用权重
HOSPITAL_BETA=0.5   # 局部价值权重
HOSPITAL_GAMMA=0.2  # 理想状态偏差权重

# ===== 性能优化配置 =====
# LLM请求超时 (秒)
HOSPITAL_LLM_TIMEOUT=30.0

# LLM响应缓存
HOSPITAL_ENABLE_LLM_CACHE=true

# 历史数据保留长度
HOSPITAL_HISTORY_LIMIT=100

# ===== 调试配置 =====
# 日志级别: DEBUG, INFO, WARNING, ERROR
HOSPITAL_LOG_LEVEL=INFO

# 是否显示详细的智能体决策过程
HOSPITAL_VERBOSE_DECISIONS=false

# 是否保存决策历史
HOSPITAL_SAVE_DECISION_HISTORY=true

# ===== 本地模型配置 (仅当LLM_PROVIDER=local时使用) =====
# Ollama服务地址
OLLAMA_BASE_URL=http://localhost:11434

# 本地模型名称
LOCAL_MODEL_NAME=llama2:7b

# ===== 高级配置 =====
# 智能体并发处理数量
HOSPITAL_AGENT_CONCURRENCY=5

# WebSocket连接超时
HOSPITAL_WEBSOCKET_TIMEOUT=60

# 仿真步长 (毫秒)
HOSPITAL_SIMULATION_STEP_MS=1000

# 议会召开间隔 (仿真步数)
HOSPITAL_PARLIAMENT_INTERVAL=7

# 危机发生概率
HOSPITAL_CRISIS_PROBABILITY=0.1