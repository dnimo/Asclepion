"""
è°ƒè¯•Mock LLMå“åº”
"""

import sys
from pathlib import Path
import numpy as np

project_root = Path(__file__).parent
sys.path.append(str(project_root))

from src.hospital_governance.agents.llm_action_generator import MockLLMProvider, LLMConfig

def debug_mock_response():
    print("ğŸ” è°ƒè¯•Mock LLMå“åº”")
    print("=" * 50)
    
    # åˆ›å»ºMockæä¾›è€…
    config = LLMConfig(model_name="mock")
    mock_provider = MockLLMProvider(config)
    
    # æ¨¡æ‹Ÿä¸åŒçš„æç¤º
    test_prompts = [
        "ä½œä¸ºdoctorsè§’è‰²ï¼ŒåŸºäºå½“å‰è§‚æµ‹[0.5, 0.6, 0.4, 0.7]ï¼Œè€ƒè™‘ç¥åœ£æ³•å…¸è§„åˆ™ï¼Œå»ºè®®é‡‡å–çš„è¡ŒåŠ¨ï¼š",
        "æé«˜åŒ»ç–—è´¨é‡æ ‡å‡†",
        "ç”³è¯·æ›´å¤šèµ„æº", 
        "åŸºäºå½“å‰æƒ…å†µè€ƒè™‘æœ€ä½³å†³ç­–"
    ]
    
    contexts = [
        {'role': 'doctors'},
        {'role': 'interns'},
        {'role': 'patients'}
    ]
    
    for i, prompt in enumerate(test_prompts):
        print(f"\\nğŸ§ª æµ‹è¯•æç¤º {i+1}: {prompt[:50]}...")
        for context in contexts:
            response = mock_provider.generate_text_sync(prompt, context)
            print(f"  è§’è‰² {context['role']}: {response}")

if __name__ == "__main__":
    debug_mock_response()