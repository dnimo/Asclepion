#!/usr/bin/env python3
"""
åŒ»é™¢æ²»ç†ç³»ç»Ÿå®Œæ•´ä»¿çœŸ
é›†æˆLLMå†³ç­–ã€åˆ†å¸ƒå¼æ§åˆ¶ã€ç¥åœ£æ³•å…¸è§„åˆ™å¼•æ“
"""

import numpy as np
import asyncio
import json
import time
import os
from typing import Dict, List, Any, Optional
from dataclasses import dataclass, asdict
import matplotlib.pyplot as plt
import yaml

# ç®€åŒ–å¯¼å…¥ï¼Œé¿å…å¤æ‚ä¾èµ–
class SimulationConfig:
    """ä»¿çœŸé…ç½®"""
    def __init__(self):
        # ä»¿çœŸå‚æ•°
        self.duration = 100  # ä»¿çœŸæ—¶é•¿
        self.dt = 0.1  # æ—¶é—´æ­¥é•¿
        self.num_agents = 5  # æ™ºèƒ½ä½“æ•°é‡
        
        # LLMé…ç½®
        self.llm_provider = 'mock'  # å¯é€‰ï¼šopenai, anthropic, local, mock
        self.llm_model = 'gpt-4'
        self.api_key = None
        
        # ç³»ç»Ÿé…ç½®
        self.system_dim = 16  # ç³»ç»ŸçŠ¶æ€ç»´åº¦
        self.control_dim = 17  # æ§åˆ¶è¾“å…¥ç»´åº¦
        self.disturbance_level = 0.1  # æ‰°åŠ¨å¼ºåº¦
        
        # è¾“å‡ºé…ç½®
        self.save_results = True
        self.plot_results = True
        self.export_data = True
        self.output_dir = 'simulation_results'

class HospitalSystem:
    """åŒ»é™¢ç³»ç»ŸåŠ¨åŠ›å­¦æ¨¡å‹"""
    
    def __init__(self, config: SimulationConfig):
        self.config = config
        self.state_dim = config.system_dim
        self.control_dim = config.control_dim
        
        # ç³»ç»ŸçŸ©é˜µï¼ˆç®€åŒ–ç‰ˆæœ¬ï¼‰
        self.A = np.eye(self.state_dim) + 0.1 * np.random.randn(self.state_dim, self.state_dim) * 0.1
        self.B = np.random.randn(self.state_dim, self.control_dim) * 0.2
        self.C = np.eye(self.state_dim)  # è§‚æµ‹çŸ©é˜µ
        
        # åˆå§‹çŠ¶æ€
        self.x = np.random.rand(self.state_dim) * 0.5
        self.x_ref = np.zeros(self.state_dim)  # å‚è€ƒçŠ¶æ€
        
        # æ‰°åŠ¨æ¨¡å‹
        self.disturbance_variance = config.disturbance_level
        
    def update(self, u: np.ndarray, dt: float) -> np.ndarray:
        """æ›´æ–°ç³»ç»ŸçŠ¶æ€"""
        # æ‰°åŠ¨
        w = np.random.normal(0, self.disturbance_variance, self.state_dim)
        
        # çŠ¶æ€æ›´æ–°ï¼šx_{k+1} = A*x_k + B*u_k + w_k
        self.x = np.dot(self.A, self.x) + np.dot(self.B, u) + w * dt
        
        # ä¿æŒçŠ¶æ€åœ¨åˆç†èŒƒå›´å†…
        self.x = np.clip(self.x, -2.0, 2.0)
        
        return self.get_observation()
    
    def get_observation(self) -> np.ndarray:
        """è·å–è§‚æµ‹"""
        # æ·»åŠ è§‚æµ‹å™ªå£°
        noise = np.random.normal(0, 0.01, self.state_dim)
        return np.dot(self.C, self.x) + noise
    
    def get_state(self) -> np.ndarray:
        """è·å–çœŸå®çŠ¶æ€"""
        return self.x.copy()

class SimpleRuleEngine:
    """ç®€åŒ–çš„è§„åˆ™å¼•æ“"""
    
    def __init__(self):
        self.rules = {
            'ETHICS_001': {
                'name': 'æ‚£è€…ç”Ÿå‘½æƒä¼˜å…ˆ',
                'priority': 1,
                'condition': lambda state: np.mean(state[:4]) < 0.3,  # å¥åº·æŒ‡æ ‡ä½
                'constraints': {'min_health_level': 0.5, 'min_quality_control': 0.4}
            },
            'RESOURCE_001': {
                'name': 'èµ„æºå…¬å¹³åˆ†é…',
                'priority': 2,
                'condition': lambda state: np.std(state[4:8]) > 0.5,  # èµ„æºåˆ†å¸ƒä¸å‡
                'constraints': {'max_resource_waste': 0.2, 'min_efficiency': 0.6}
            },
            'CRISIS_001': {
                'name': 'å±æœºåº”æ€¥å“åº”',
                'priority': 1,
                'condition': lambda state: np.max(np.abs(state)) > 1.5,  # ç³»ç»Ÿå¼‚å¸¸
                'constraints': {'max_response_time': 0.1, 'min_emergency_reserve': 0.8}
            }
        }
    
    def evaluate(self, state: np.ndarray) -> Dict[str, Any]:
        """è¯„ä¼°è§„åˆ™å¹¶è¿”å›çº¦æŸ"""
        active_rules = []
        constraints = {}
        
        for rule_id, rule in self.rules.items():
            if rule['condition'](state):
                active_rules.append(rule_id)
                constraints.update(rule['constraints'])
        
        return {
            'active_rules': active_rules,
            'ethical_constraints': constraints,
            'crisis_level': 'high' if 'CRISIS_001' in active_rules else 'normal'
        }

class SimpleLLMProvider:
    """ç®€åŒ–çš„LLMæä¾›è€…"""
    
    def __init__(self, provider_type: str = 'mock'):
        self.provider_type = provider_type
        self.role_templates = {
            'doctors': self._doctor_decision,
            'interns': self._intern_decision,
            'patients': self._patient_decision,
            'accountants': self._accountant_decision,
            'government': self._government_decision
        }
    
    def generate_action(self, role: str, observation: np.ndarray, constraints: Dict) -> np.ndarray:
        """ç”Ÿæˆè¡ŒåŠ¨å†³ç­–"""
        if self.provider_type == 'mock':
            return self.role_templates.get(role, self._default_decision)(observation, constraints)
        else:
            # è¿™é‡Œå¯ä»¥é›†æˆçœŸå®çš„LLM API
            return self._call_real_llm(role, observation, constraints)
    
    def _doctor_decision(self, obs: np.ndarray, constraints: Dict) -> np.ndarray:
        """åŒ»ç”Ÿå†³ç­–é€»è¾‘"""
        # åŸºäºè§‚æµ‹å’Œçº¦æŸçš„æ™ºèƒ½å†³ç­–
        quality_concern = obs[0] if len(obs) > 0 else 0.5
        resource_need = obs[1] if len(obs) > 1 else 0.3
        
        action = np.array([
            0.6 if quality_concern < 0.4 else 0.2,  # è´¨é‡æ”¹è¿›
            0.5 if resource_need < 0.3 else 0.1,   # èµ„æºç”³è¯·
            -0.3 if np.mean(obs[:4]) > 0.7 else 0.1,  # å·¥ä½œè´Ÿè·è°ƒæ•´
            0.7 if constraints.get('min_quality_control', 0) > 0.3 else 0.3  # å®‰å…¨æªæ–½
        ])
        
        # åº”ç”¨çº¦æŸ
        if 'min_quality_control' in constraints:
            action[3] = max(action[3], constraints['min_quality_control'])
        
        return np.clip(action, -1, 1)
    
    def _intern_decision(self, obs: np.ndarray, constraints: Dict) -> np.ndarray:
        """å®ä¹ åŒ»ç”Ÿå†³ç­–é€»è¾‘"""
        training_need = 0.6 if np.mean(obs[:3]) < 0.4 else 0.2
        workload_pressure = obs[2] if len(obs) > 2 else 0.5
        
        action = np.array([
            training_need,  # åŸ¹è®­éœ€æ±‚
            -0.4 if workload_pressure > 0.7 else 0.1,  # å·¥ä½œè°ƒæ•´
            0.5  # å‘å±•è®¡åˆ’
        ])
        
        return np.clip(action, -1, 1)
    
    def _patient_decision(self, obs: np.ndarray, constraints: Dict) -> np.ndarray:
        """æ‚£è€…å†³ç­–é€»è¾‘"""
        satisfaction = obs[4] if len(obs) > 4 else 0.5
        
        action = np.array([
            0.7 if satisfaction < 0.4 else 0.2,  # æœåŠ¡æ”¹å–„
            0.6 if obs[5] < 0.3 else 0.1,  # å¯åŠæ€§ä¼˜åŒ–
            0.5 if constraints.get('min_health_level', 0) > 0.4 else 0.2  # å®‰å…¨å…³æ³¨
        ])
        
        return np.clip(action, -1, 1)
    
    def _accountant_decision(self, obs: np.ndarray, constraints: Dict) -> np.ndarray:
        """ä¼šè®¡å†³ç­–é€»è¾‘"""
        cost_efficiency = obs[8] if len(obs) > 8 else 0.5
        
        action = np.array([
            0.8 if cost_efficiency < 0.4 else 0.3,  # æˆæœ¬æ§åˆ¶
            0.6 if constraints.get('min_efficiency', 0) > 0.5 else 0.2,  # æ•ˆç‡æå‡
            0.4  # é¢„ç®—ä¼˜åŒ–
        ])
        
        return np.clip(action, -1, 1)
    
    def _government_decision(self, obs: np.ndarray, constraints: Dict) -> np.ndarray:
        """æ”¿åºœå†³ç­–é€»è¾‘"""
        system_stability = np.std(obs)
        
        action = np.array([
            0.7 if system_stability > 0.5 else 0.2,  # ç›‘ç®¡æªæ–½
            0.5,  # æ”¿ç­–è°ƒæ•´
            0.6 if len(constraints) > 2 else 0.1  # åè°ƒè¡ŒåŠ¨
        ])
        
        return np.clip(action, -1, 1)
    
    def _default_decision(self, obs: np.ndarray, constraints: Dict) -> np.ndarray:
        """é»˜è®¤å†³ç­–"""
        return np.random.rand(4) * 0.4 - 0.2
    
    def _call_real_llm(self, role: str, observation: np.ndarray, constraints: Dict) -> np.ndarray:
        """è°ƒç”¨çœŸå®LLM APIï¼ˆå¾…å®ç°ï¼‰"""
        # TODO: é›†æˆçœŸå®LLM API
        return self._default_decision(observation, constraints)

class MultiAgentController:
    """å¤šæ™ºèƒ½ä½“æ§åˆ¶å™¨"""
    
    def __init__(self, config: SimulationConfig):
        self.config = config
        self.llm_provider = SimpleLLMProvider(config.llm_provider)
        
        # è§‚æµ‹æ©ç  - å®šä¹‰æ¯ä¸ªè§’è‰²èƒ½è§‚æµ‹åˆ°çš„çŠ¶æ€
        self.observation_masks = {
            'doctors': slice(0, 16),  # å…¨éƒ¨çŠ¶æ€
            'interns': slice(0, 12),  # å‰12ä¸ªçŠ¶æ€
            'patients': slice(4, 12), # è´¢åŠ¡å’Œè´¨é‡çŠ¶æ€
            'accountants': slice(8, 12), # è´¢åŠ¡çŠ¶æ€
            'government': [0, 1, 2, 3, 12, 13, 14, 15]  # èµ„æºå’Œä¼¦ç†çŠ¶æ€
        }
        
        # æ§åˆ¶åˆ†é…
        self.control_allocation = {
            'doctors': slice(0, 4),
            'interns': slice(4, 8),
            'patients': slice(8, 11),
            'accountants': slice(11, 14),
            'government': slice(14, 17)
        }
    
    def compute_control(self, full_state: np.ndarray, holy_code_state: Dict) -> np.ndarray:
        """è®¡ç®—å¤šæ™ºèƒ½ä½“æ§åˆ¶ä¿¡å·"""
        u_global = np.zeros(self.config.control_dim)
        
        for role in ['doctors', 'interns', 'patients', 'accountants', 'government']:
            # è·å–å±€éƒ¨è§‚æµ‹
            mask = self.observation_masks[role]
            if isinstance(mask, slice):
                local_obs = full_state[mask]
            else:
                local_obs = full_state[mask]
            
            # ç”Ÿæˆå±€éƒ¨æ§åˆ¶
            local_control = self.llm_provider.generate_action(
                role, local_obs, holy_code_state.get('ethical_constraints', {})
            )
            
            # åˆ†é…åˆ°å…¨å±€æ§åˆ¶å‘é‡
            control_slice = self.control_allocation[role]
            u_global[control_slice] = local_control[:len(range(*control_slice.indices(self.config.control_dim)))]
        
        return u_global

class HospitalSimulation:
    """åŒ»é™¢æ²»ç†ç³»ç»Ÿä»¿çœŸä¸»ç±»"""
    
    def __init__(self, config: SimulationConfig = None):
        self.config = config or SimulationConfig()
        
        # åˆå§‹åŒ–ç»„ä»¶
        self.system = HospitalSystem(self.config)
        self.rule_engine = SimpleRuleEngine()
        self.controller = MultiAgentController(self.config)
        
        # æ•°æ®è®°å½•
        self.time_history = []
        self.state_history = []
        self.control_history = []
        self.rule_history = []
        self.performance_history = []
        
        # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
        os.makedirs(self.config.output_dir, exist_ok=True)
    
    def run_simulation(self):
        """è¿è¡Œå®Œæ•´ä»¿çœŸ"""
        print("ğŸš€ å¼€å§‹åŒ»é™¢æ²»ç†ç³»ç»Ÿä»¿çœŸ...")
        print(f"ä»¿çœŸæ—¶é•¿: {self.config.duration} æ­¥")
        print(f"LLMæä¾›è€…: {self.config.llm_provider}")
        print(f"ç³»ç»Ÿç»´åº¦: {self.config.system_dim}D çŠ¶æ€, {self.config.control_dim}D æ§åˆ¶")
        
        start_time = time.time()
        
        for step in range(self.config.duration):
            # è·å–å½“å‰çŠ¶æ€å’Œè§‚æµ‹
            state = self.system.get_state()
            observation = self.system.get_observation()
            
            # è¯„ä¼°ç¥åœ£æ³•å…¸è§„åˆ™
            holy_code_state = self.rule_engine.evaluate(state)
            
            # è®¡ç®—æ§åˆ¶è¾“å…¥
            control = self.controller.compute_control(observation, holy_code_state)
            
            # æ›´æ–°ç³»ç»Ÿ
            next_observation = self.system.update(control, self.config.dt)
            
            # è®°å½•æ•°æ®
            self._record_step(step, state, control, holy_code_state)
            
            # è¿›åº¦æ˜¾ç¤º
            if step % 20 == 0:
                print(f"æ­¥éª¤ {step}/{self.config.duration}, æ¿€æ´»è§„åˆ™: {len(holy_code_state['active_rules'])}")
        
        simulation_time = time.time() - start_time
        print(f"âœ… ä»¿çœŸå®Œæˆï¼Œè€—æ—¶: {simulation_time:.2f}ç§’")
        
        # åˆ†æç»“æœ
        self._analyze_results()
        
        # ä¿å­˜å’Œå¯è§†åŒ–
        if self.config.save_results:
            self._save_results()
        
        if self.config.plot_results:
            self._plot_results()
        
        return self._get_summary()
    
    def _record_step(self, step: int, state: np.ndarray, control: np.ndarray, holy_code_state: Dict):
        """è®°å½•å•æ­¥æ•°æ®"""
        self.time_history.append(step * self.config.dt)
        self.state_history.append(state.copy())
        self.control_history.append(control.copy())
        self.rule_history.append(holy_code_state.copy())
        
        # è®¡ç®—æ€§èƒ½æŒ‡æ ‡
        performance = {
            'stability': np.linalg.norm(state),
            'control_effort': np.linalg.norm(control),
            'rule_compliance': len(holy_code_state['active_rules']),
            'system_health': 1.0 / (1.0 + np.linalg.norm(state - self.system.x_ref))
        }
        self.performance_history.append(performance)
    
    def _analyze_results(self):
        """åˆ†æä»¿çœŸç»“æœ"""
        print("\\nğŸ“Š ä»¿çœŸç»“æœåˆ†æ:")
        
        # ç³»ç»Ÿç¨³å®šæ€§
        final_stability = self.performance_history[-1]['stability']
        avg_stability = np.mean([p['stability'] for p in self.performance_history])
        print(f"  æœ€ç»ˆç¨³å®šæ€§: {final_stability:.3f}")
        print(f"  å¹³å‡ç¨³å®šæ€§: {avg_stability:.3f}")
        
        # æ§åˆ¶åŠªåŠ›
        avg_control_effort = np.mean([p['control_effort'] for p in self.performance_history])
        print(f"  å¹³å‡æ§åˆ¶åŠªåŠ›: {avg_control_effort:.3f}")
        
        # è§„åˆ™æ¿€æ´»ç»Ÿè®¡
        total_rule_activations = sum(p['rule_compliance'] for p in self.performance_history)
        print(f"  æ€»è§„åˆ™æ¿€æ´»æ¬¡æ•°: {total_rule_activations}")
        
        # ç³»ç»Ÿå¥åº·åº¦
        avg_health = np.mean([p['system_health'] for p in self.performance_history])
        print(f"  å¹³å‡ç³»ç»Ÿå¥åº·åº¦: {avg_health:.3f}")
        
        # è§„åˆ™æ¿€æ´»é¢‘ç‡
        rule_counts = {}
        for rule_state in self.rule_history:
            for rule in rule_state['active_rules']:
                rule_counts[rule] = rule_counts.get(rule, 0) + 1
        
        print(f"  è§„åˆ™æ¿€æ´»é¢‘ç‡:")
        for rule, count in sorted(rule_counts.items(), key=lambda x: x[1], reverse=True):
            print(f"    {rule}: {count} æ¬¡")
    
    def _save_results(self):
        """ä¿å­˜ç»“æœåˆ°æ–‡ä»¶"""
        print("\\nğŸ’¾ ä¿å­˜ä»¿çœŸç»“æœ...")
        
        # ä¿å­˜é…ç½®
        with open(f"{self.config.output_dir}/config.json", 'w') as f:
            json.dump(asdict(self.config), f, indent=2)
        
        # ä¿å­˜æ•°æ®
        results = {
            'time': self.time_history,
            'states': [state.tolist() for state in self.state_history],
            'controls': [control.tolist() for control in self.control_history],
            'rules': self.rule_history,
            'performance': self.performance_history
        }
        
        with open(f"{self.config.output_dir}/simulation_data.json", 'w') as f:
            json.dump(results, f, indent=2)
        
        # ä¿å­˜æ‘˜è¦
        summary = self._get_summary()
        with open(f"{self.config.output_dir}/summary.json", 'w') as f:
            json.dump(summary, f, indent=2)
        
        print(f"  ç»“æœå·²ä¿å­˜åˆ°: {self.config.output_dir}/")
    
    def _plot_results(self):
        """ç»˜åˆ¶ç»“æœå›¾è¡¨"""
        print("\\nğŸ“ˆ ç”Ÿæˆå¯è§†åŒ–å›¾è¡¨...")
        
        fig, axes = plt.subplots(2, 2, figsize=(15, 10))
        
        # ç³»ç»ŸçŠ¶æ€è½¨è¿¹
        axes[0, 0].plot(self.time_history, [s[0] for s in self.state_history], label='çŠ¶æ€1')
        axes[0, 0].plot(self.time_history, [s[1] for s in self.state_history], label='çŠ¶æ€2')
        axes[0, 0].plot(self.time_history, [s[2] for s in self.state_history], label='çŠ¶æ€3')
        axes[0, 0].set_title('å…³é”®ç³»ç»ŸçŠ¶æ€')
        axes[0, 0].set_xlabel('æ—¶é—´')
        axes[0, 0].legend()
        axes[0, 0].grid(True)
        
        # æ§åˆ¶ä¿¡å·
        axes[0, 1].plot(self.time_history, [c[0] for c in self.control_history], label='åŒ»ç”Ÿæ§åˆ¶')
        axes[0, 1].plot(self.time_history, [c[4] for c in self.control_history], label='å®ä¹ åŒ»ç”Ÿæ§åˆ¶')
        axes[0, 1].plot(self.time_history, [c[8] for c in self.control_history], label='æ‚£è€…æ§åˆ¶')
        axes[0, 1].set_title('å¤šæ™ºèƒ½ä½“æ§åˆ¶ä¿¡å·')
        axes[0, 1].set_xlabel('æ—¶é—´')
        axes[0, 1].legend()
        axes[0, 1].grid(True)
        
        # æ€§èƒ½æŒ‡æ ‡
        axes[1, 0].plot(self.time_history, [p['stability'] for p in self.performance_history], label='ç¨³å®šæ€§')
        axes[1, 0].plot(self.time_history, [p['system_health'] for p in self.performance_history], label='ç³»ç»Ÿå¥åº·åº¦')
        axes[1, 0].set_title('ç³»ç»Ÿæ€§èƒ½æŒ‡æ ‡')
        axes[1, 0].set_xlabel('æ—¶é—´')
        axes[1, 0].legend()
        axes[1, 0].grid(True)
        
        # è§„åˆ™æ¿€æ´»
        rule_activation = [len(r['active_rules']) for r in self.rule_history]
        axes[1, 1].plot(self.time_history, rule_activation, 'r-', label='æ¿€æ´»è§„åˆ™æ•°')
        axes[1, 1].set_title('ç¥åœ£æ³•å…¸è§„åˆ™æ¿€æ´»')
        axes[1, 1].set_xlabel('æ—¶é—´')
        axes[1, 1].set_ylabel('æ¿€æ´»è§„åˆ™æ•°é‡')
        axes[1, 1].legend()
        axes[1, 1].grid(True)
        
        plt.tight_layout()
        plt.savefig(f"{self.config.output_dir}/simulation_results.png", dpi=300, bbox_inches='tight')
        print(f"  å›¾è¡¨å·²ä¿å­˜åˆ°: {self.config.output_dir}/simulation_results.png")
        
        if self.config.plot_results:
            plt.show()
    
    def _get_summary(self) -> Dict[str, Any]:
        """ç”Ÿæˆä»¿çœŸæ‘˜è¦"""
        return {
            'simulation_config': asdict(self.config),
            'final_performance': self.performance_history[-1] if self.performance_history else {},
            'average_performance': {
                'stability': np.mean([p['stability'] for p in self.performance_history]),
                'control_effort': np.mean([p['control_effort'] for p in self.performance_history]),
                'system_health': np.mean([p['system_health'] for p in self.performance_history])
            },
            'rule_statistics': self._get_rule_statistics(),
            'simulation_duration': len(self.time_history) * self.config.dt
        }
    
    def _get_rule_statistics(self) -> Dict[str, Any]:
        """è·å–è§„åˆ™ç»Ÿè®¡"""
        rule_counts = {}
        for rule_state in self.rule_history:
            for rule in rule_state['active_rules']:
                rule_counts[rule] = rule_counts.get(rule, 0) + 1
        
        return {
            'total_activations': sum(rule_counts.values()),
            'unique_rules_activated': len(rule_counts),
            'activation_frequency': rule_counts,
            'most_active_rule': max(rule_counts.items(), key=lambda x: x[1])[0] if rule_counts else None
        }

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ¥ åŒ»é™¢æ²»ç†ç³»ç»ŸLLMé©±åŠ¨ä»¿çœŸ")
    print("=" * 60)
    
    # åˆ›å»ºé…ç½®
    config = SimulationConfig()
    config.duration = 50  # å‡å°‘æ­¥æ•°ä»¥ä¾¿å¿«é€Ÿæµ‹è¯•
    config.llm_provider = 'mock'  # ä½¿ç”¨æ¨¡æ‹ŸLLM
    config.save_results = True
    config.plot_results = False  # å…³é—­è‡ªåŠ¨æ˜¾ç¤ºå›¾è¡¨
    
    # è¿è¡Œä»¿çœŸ
    simulation = HospitalSimulation(config)
    summary = simulation.run_simulation()
    
    print("\\nğŸ‰ ä»¿çœŸå®Œæˆï¼")
    print("=" * 60)
    print("æ‘˜è¦:")
    print(f"  ä»¿çœŸæ—¶é•¿: {summary['simulation_duration']:.1f} æ—¶é—´å•ä½")
    print(f"  æœ€ç»ˆç³»ç»Ÿå¥åº·åº¦: {summary['final_performance'].get('system_health', 0):.3f}")
    print(f"  å¹³å‡ç¨³å®šæ€§: {summary['average_performance']['stability']:.3f}")
    print(f"  æ€»è§„åˆ™æ¿€æ´»: {summary['rule_statistics']['total_activations']} æ¬¡")
    print(f"  æœ€æ´»è·ƒè§„åˆ™: {summary['rule_statistics'].get('most_active_rule', 'None')}")

if __name__ == '__main__':
    main()