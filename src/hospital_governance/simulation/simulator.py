import numpy as np
import asyncio
import logging
from typing import Dict, List, Any, Tuple, Optional, Callable
import time
import json
from dataclasses import dataclass
import yaml
import os
import traceback

# å¯¼å…¥coreæ•°å­¦æ¨¡å—
try:
    from ..core.kallipolis_mathematical_core import SystemState, KallipolisMedicalSystem
    from ..core.system_dynamics import SystemDynamics
    from ..core.system_matrices import SystemMatrixGenerator
    from ..core.state_space import StateSpace
    HAS_CORE_MATH = True
except ImportError as e:
    logger.warning(f"Coreæ•°å­¦æ¨¡å—å¯¼å…¥å¤±è´¥: {e}")
    HAS_CORE_MATH = False

# å¯¼å…¥agentsåŒ…çš„è¯¦ç»†åŠŸèƒ½
from ..agents.role_agents import RoleAgent, RoleManager, AgentConfig
from ..agents.multi_agent_coordinator import MultiAgentInteractionEngine, InteractionConfig
from ..agents.llm_action_generator import LLMActionGenerator, LLMConfig
from ..agents.role_agents_old import ParliamentMemberAgent
from ..agents.learning_models import MADDPGModel, LearningModel
from ..control.distributed_control import DistributedControlSystem

# è®¾ç½®æ—¥å¿—
logger = logging.getLogger(__name__)

@dataclass
class SimulationConfig:
    """ä»¿çœŸé…ç½®"""
    max_steps: int = 14
    time_scale: float = 1.0
    meeting_interval: int = 7  # æ¯7æ­¥ä¸¾è¡Œè®®ä¼šä¼šè®®
    enable_learning: bool = True
    enable_holy_code: bool = True
    enable_crises: bool = True
    enable_behavior_models: bool = True
    enable_llm_integration: bool = False
    enable_scenario_runner: bool = True
    data_logging_interval: int = 10
    stability_check_interval: int = 50
    crisis_probability: float = 0.03
    
    # é›†æˆé…ç½®
    holy_code_config: Optional[Any] = None
    interaction_config: Optional[Any] = None
    scenario_config: Optional[Any] = None

class KallipolisSimulator:
    """KallipolisåŒ»ç–—å…±å’Œå›½æ¨¡æ‹Ÿå™¨
    
    ä»¿çœŸå¾ªç¯çš„ä¸»ä½“ï¼Œè´Ÿè´£ï¼š
    1. ç³»ç»ŸçŠ¶æ€æ›´æ–°
    2. æ™ºèƒ½ä½“å†³ç­–
    3. è®®ä¼šä¼šè®®
    4. å±æœºå¤„ç†
    5. æ•°æ®æ¨é€
    """
    
    def __init__(self, config: SimulationConfig = None):
        self.config = config or SimulationConfig()
        
        # ä»¿çœŸçŠ¶æ€
        self.current_step = 0
        self.simulation_time = 0.0
        self.is_running = False
        self.is_paused = False
        
        # æ•°æ®å›è°ƒæœºåˆ¶
        self.data_callback: Optional[Callable] = None
        
        # å†å²è®°å½•
        self.decision_history = []
        self.interaction_history = []
        self.crisis_history = []
        self.performance_history = []
        self.parliament_history = []
        
        # æ ¸å¿ƒç»„ä»¶åˆå§‹åŒ–
        self.role_manager = None
        self.holy_code_manager = None
        self.learning_model = None
        self.maddpg_model = None  # MADDPGå¤šæ™ºèƒ½ä½“å­¦ä¹ æ¨¡å‹
        self.experience_buffer = []  # ç»éªŒå›æ”¾ç¼“å†²åŒº
        self.distributed_controller = None  # åˆ†å¸ƒå¼æ§åˆ¶ç³»ç»Ÿ
        self.interaction_engine = None
        self.coordinator = None
        self.llm_action_generator = None
        
        # åˆå§‹åŒ–æ ¸å¿ƒæ•°å­¦ç³»ç»Ÿ
        if HAS_CORE_MATH:
            self.core_system = KallipolisMedicalSystem()
            self.system_state = self.core_system.current_state
            
            # åˆå§‹åŒ–ç³»ç»ŸåŠ¨åŠ›å­¦
            system_matrices = SystemMatrixGenerator.generate_nominal_matrices()
            self.system_matrices = system_matrices  # ä¿å­˜ä¸ºå®ä¾‹å˜é‡
            self.system_dynamics = SystemDynamics(system_matrices)
            
            # åˆå§‹åŒ–çŠ¶æ€ç©ºé—´ç®¡ç†
            self.state_space = StateSpace(self.system_state.to_vector())
        else:
            # å›é€€åˆ°ç®€åŒ–çŠ¶æ€
            self._legacy_system_state = {
                'medical_quality': 0.85, 'patient_safety': 0.9, 'care_quality': 0.8,
                'resource_adequacy': 0.7, 'resource_utilization': 0.75, 'resource_access': 0.8,
                'education_quality': 0.7, 'training_hours': 30.0, 'mentorship_availability': 0.6,
                'career_development': 0.65, 'financial_health': 0.8, 'cost_efficiency': 0.75,
                'revenue_growth': 0.7, 'patient_satisfaction': 0.75, 'accessibility': 0.8,
                'waiting_times': 0.3, 'staff_satisfaction': 0.7, 'workload': 0.6,
                'salary_satisfaction': 0.65, 'system_stability': 0.8, 'ethics_compliance': 0.85,
                'regulatory_compliance': 0.9, 'public_trust': 0.75, 'overall_performance': 0.78,
                'crisis_severity': 0.0
            }
            self.system_state = None
        
        # åˆå§‹åŒ–çœŸå®çš„æ™ºèƒ½ä½“å¯¹è±¡
        self.agent_objects = {}  # å­˜å‚¨RoleAgentå¯¹è±¡
        self.agents = {  # ä¿æŒå…¼å®¹æ€§çš„ç®€åŒ–çŠ¶æ€
            'doctors': {
                'name': 'åŒ»ç”Ÿç¾¤ä½“',
                'performance': 0.8,
                'last_decision': None,
                'payoff': 0.0,
                'strategy_params': np.random.uniform(0.3, 0.7, 3),
                'active': True
            },
            'interns': {
                'name': 'å®ä¹ ç”Ÿç¾¤ä½“',
                'performance': 0.7,
                'last_decision': None,
                'payoff': 0.0,
                'strategy_params': np.random.uniform(0.2, 0.6, 3),
                'active': True
            },
            'patients': {
                'name': 'æ‚£è€…ä»£è¡¨',
                'performance': 0.75,
                'last_decision': None,
                'payoff': 0.0,
                'strategy_params': np.random.uniform(0.4, 0.8, 3),
                'active': True
            },
            'accountants': {
                'name': 'ä¼šè®¡ç¾¤ä½“',
                'performance': 0.8,
                'last_decision': None,
                'payoff': 0.0,
                'strategy_params': np.random.uniform(0.5, 0.9, 3),
                'active': True
            },
            'government': {
                'name': 'æ”¿åºœç›‘ç®¡',
                'performance': 0.75,
                'last_decision': None,
                'payoff': 0.0,
                'strategy_params': np.random.uniform(0.3, 0.7, 3),
                'active': True
            }
        }
        
        # åœ¨agentså®šä¹‰ä¹‹ååˆå§‹åŒ–LLMå’Œæ™ºèƒ½ä½“ç³»ç»Ÿ
        self._initialize_agents_and_llm()
        
        logger.info("ğŸ¥ KallipolisSimulatoråˆå§‹åŒ–å®Œæˆ")
    
    def _convert_state_to_dict(self) -> Dict[str, float]:
        """å°†SystemStateå¯¹è±¡è½¬æ¢ä¸ºå­—å…¸æ ¼å¼ï¼Œä¿æŒå‘åå…¼å®¹æ€§"""
        if HAS_CORE_MATH and hasattr(self.system_state, 'to_vector'):
            # ä½¿ç”¨coreæ¨¡å—çš„SystemState
            state_vector = self.system_state.to_vector()
            state_names = self.system_state.get_component_names()
            
            # åˆ›å»ºæ˜ å°„å­—å…¸
            state_dict = dict(zip([
                'medical_resource_utilization', 'patient_waiting_time', 'financial_indicator', 'ethical_compliance',
                'education_training_quality', 'intern_satisfaction', 'professional_development', 'mentorship_effectiveness',
                'patient_satisfaction', 'service_accessibility', 'care_quality_index', 'safety_incident_rate',
                'operational_efficiency', 'staff_workload_balance', 'crisis_response_capability', 'regulatory_compliance_score'
            ], state_vector))
            
            # æ·»åŠ å…¼å®¹æ€§æ˜ å°„
            legacy_mapping = {
                'medical_quality': state_dict['care_quality_index'],
                'patient_safety': 1.0 - state_dict['safety_incident_rate'],
                'care_quality': state_dict['care_quality_index'],
                'resource_adequacy': state_dict['medical_resource_utilization'],
                'resource_utilization': state_dict['medical_resource_utilization'], 
                'resource_access': state_dict['service_accessibility'],
                'education_quality': state_dict['education_training_quality'],
                'training_hours': 30.0 + state_dict['education_training_quality'] * 10,
                'mentorship_availability': state_dict['mentorship_effectiveness'],
                'career_development': state_dict['professional_development'],
                'financial_health': state_dict['financial_indicator'],
                'cost_efficiency': state_dict['operational_efficiency'],
                'revenue_growth': state_dict['financial_indicator'],
                'accessibility': state_dict['service_accessibility'],
                'waiting_times': state_dict['patient_waiting_time'],
                'staff_satisfaction': state_dict['intern_satisfaction'],
                'workload': state_dict['staff_workload_balance'],
                'salary_satisfaction': state_dict['intern_satisfaction'],
                'system_stability': state_dict['crisis_response_capability'],
                'ethics_compliance': state_dict['ethical_compliance'],
                'regulatory_compliance': state_dict['regulatory_compliance_score'],
                'public_trust': state_dict['regulatory_compliance_score'],
                'overall_performance': np.mean(list(state_dict.values())),
                'crisis_severity': 1.0 - state_dict['crisis_response_capability']
            }
            
            state_dict.update(legacy_mapping)
            return state_dict
        else:
            # å›é€€åˆ°åŸæœ‰å­—å…¸æ ¼å¼
            return getattr(self, '_legacy_system_state', {
                'medical_quality': 0.85, 'patient_safety': 0.9, 'care_quality': 0.8,
                'resource_adequacy': 0.7, 'resource_utilization': 0.75, 'resource_access': 0.8,
                'education_quality': 0.7, 'training_hours': 30.0, 'mentorship_availability': 0.6,
                'career_development': 0.65, 'financial_health': 0.8, 'cost_efficiency': 0.75,
                'revenue_growth': 0.7, 'patient_satisfaction': 0.75, 'accessibility': 0.8,
                'waiting_times': 0.3, 'staff_satisfaction': 0.7, 'workload': 0.6,
                'salary_satisfaction': 0.65, 'system_stability': 0.8, 'ethics_compliance': 0.85,
                'regulatory_compliance': 0.9, 'public_trust': 0.75, 'overall_performance': 0.78,
                'crisis_severity': 0.0
            })
    
    def _initialize_agents_and_llm(self):
        """åˆå§‹åŒ–æ™ºèƒ½ä½“å’ŒLLMç³»ç»Ÿ"""
        try:
            # åˆå§‹åŒ–LLMè¡ŒåŠ¨ç”Ÿæˆå™¨
            from ..agents.llm_action_generator import LLMActionGenerator, LLMConfig
            llm_config = LLMConfig(
                model_name="gpt-4",
                temperature=0.7,
                use_async=True
            )
            self.llm_action_generator = LLMActionGenerator(llm_config)
            
            # åˆå§‹åŒ–è§’è‰²æ™ºèƒ½ä½“ç®¡ç†å™¨
            from ..agents.role_agents import RoleAgent, RoleManager, AgentConfig
            from ..agents.multi_agent_coordinator import MultiAgentInteractionEngine, InteractionConfig
            from ..agents.role_agents_old import ParliamentMemberAgent
            
            # åˆå§‹åŒ–è§’è‰²ç®¡ç†å™¨ï¼ˆä½¿ç”¨é»˜è®¤é…ç½®ï¼‰
            self.role_manager = RoleManager()
            
            # é…ç½®äº¤äº’å¼•æ“
            interaction_config = InteractionConfig(
                use_behavior_models=True,
                use_learning_models=False,
                use_llm_generation=self.config.enable_llm_integration
            )
            self.interaction_engine = MultiAgentInteractionEngine(
                self.role_manager, interaction_config
            )
            
            # ä¸ºæ¯ä¸ªè§’è‰²åˆ›å»ºRoleAgentå¯¹è±¡
            from ..agents.role_agents import DoctorAgent, InternAgent, PatientAgent, AccountantAgent, GovernmentAgent
            
            agent_classes = {
                'doctors': DoctorAgent,
                'interns': InternAgent,
                'patients': PatientAgent,
                'accountants': AccountantAgent,
                'government': GovernmentAgent
            }
            
            for agent_id, agent_data in self.agents.items():
                try:
                    # åˆ›å»ºæ™ºèƒ½ä½“é…ç½®
                    agent_config = AgentConfig(
                        role=agent_id,
                        action_dim=4,  # åŸºäºç³»ç»ŸåŠ¨åŠ›å­¦çš„è¡ŒåŠ¨ç»´åº¦
                        observation_dim=16,  # åŸºäº16ç»´çŠ¶æ€ç©ºé—´
                        learning_rate=0.001,
                        alpha=0.3,
                        beta=0.5,
                        gamma=0.2
                    )
                    
                    # è·å–å¯¹åº”çš„æ™ºèƒ½ä½“ç±»
                    agent_class = agent_classes.get(agent_id, RoleAgent)
                    if agent_class == RoleAgent:
                        logger.warning(f"âš ï¸ æœªæ‰¾åˆ° {agent_id} çš„å…·ä½“å®ç°ç±»ï¼Œè·³è¿‡åˆ›å»º")
                        continue
                    
                    # åˆ›å»ºå…·ä½“çš„RoleAgentå¯¹è±¡
                    role_agent = agent_class(agent_config)
                    role_agent.llm_generator = self.llm_action_generator
                    
                    # å­˜å‚¨åˆ°agent_objectsä¸­
                    self.agent_objects[agent_id] = role_agent
                    
                    logger.info(f"âœ… åˆ›å»ºæ™ºèƒ½ä½“å¯¹è±¡: {agent_id} ({agent_data['name']}) -> {agent_class.__name__}")
                    
                except Exception as e:
                    logger.warning(f"âš ï¸ åˆ›å»ºæ™ºèƒ½ä½“ {agent_id} å¤±è´¥: {e}")
                    
            logger.info(f"âœ… å…±åˆ›å»º {len(self.agent_objects)} ä¸ªæ™ºèƒ½ä½“å¯¹è±¡")
            
            # åˆå§‹åŒ–MADDPGå­¦ä¹ æ¨¡å‹
            if self.config.enable_learning:
                self._initialize_maddpg_model()
            
            # åˆå§‹åŒ–åˆ†å¸ƒå¼æ§åˆ¶ç³»ç»Ÿ
            self._initialize_distributed_control()
            
            # åˆå§‹åŒ–ç¥åœ£æ³•å…¸ç®¡ç†å™¨
            from ..holy_code.holy_code_manager import HolyCodeManager, HolyCodeConfig
            holy_config = HolyCodeConfig(rule_config_path='config/holy_code_rules.yaml')
            self.holy_code_manager = HolyCodeManager(holy_config)
            
            logger.info("âœ… æ™ºèƒ½ä½“å’ŒLLMç³»ç»Ÿåˆå§‹åŒ–å®Œæˆ")
            
        except Exception as e:
            import traceback
            logger.warning(f"âš ï¸ æ™ºèƒ½ä½“ç³»ç»Ÿåˆå§‹åŒ–å¤±è´¥ï¼Œä½¿ç”¨æ¨¡æ‹Ÿæ¨¡å¼: {e}")
            logger.warning(f"è¯¦ç»†é”™è¯¯ä¿¡æ¯: {traceback.format_exc()}")
            self.llm_action_generator = None
            self.role_manager = None
            self.interaction_engine = None
            self.holy_code_manager = None
    
    def _initialize_maddpg_model(self):
        """åˆå§‹åŒ–MADDPGå¤šæ™ºèƒ½ä½“å­¦ä¹ æ¨¡å‹"""
        try:
            # å®šä¹‰æ¯ä¸ªæ™ºèƒ½ä½“çš„è¡ŒåŠ¨ç»´åº¦
            action_dims = {
                'doctors': 4,     # åŒ»ç–—è´¨é‡ã€è¯Šæ–­ç²¾åº¦ã€æ²»ç–—æ•ˆç‡ã€æ‚£è€…æ²Ÿé€š
                'interns': 4,     # å­¦ä¹ å¼ºåº¦ã€æŠ€èƒ½è®­ç»ƒã€å¯¼å¸ˆäº’åŠ¨ã€ä¸´åºŠå®è·µ
                'patients': 3,    # åé¦ˆå¼ºåº¦ã€åˆä½œç¨‹åº¦ã€æ»¡æ„åº¦è¡¨è¾¾
                'accountants': 4, # æˆæœ¬æ§åˆ¶ã€é¢„ç®—è§„åˆ’ã€è´¢åŠ¡ç›‘ç®¡ã€æ•ˆç‡ä¼˜åŒ–
                'government': 4   # æ”¿ç­–åˆ¶å®šã€ç›‘ç®¡å¼ºåº¦ã€èµ„æºåˆ†é…ã€åˆè§„è¦æ±‚
            }
            
            # ç³»ç»ŸçŠ¶æ€ç»´åº¦ï¼ˆ16ç»´çŠ¶æ€ç©ºé—´ï¼‰
            state_dim = 16
            
            # åˆå§‹åŒ–MADDPGæ¨¡å‹
            self.maddpg_model = MADDPGModel(
                state_dim=state_dim,
                action_dims=action_dims,
                hidden_dim=128,
                actor_lr=0.001,
                critic_lr=0.002,
                tau=0.01,
                gamma=0.99
            )
            
            # åˆå§‹åŒ–ç»éªŒç¼“å†²åŒº
            self.experience_buffer = []
            self.max_buffer_size = 10000
            self.batch_size = 64
            
            logger.info("âœ… MADDPGå¤šæ™ºèƒ½ä½“å­¦ä¹ æ¨¡å‹åˆå§‹åŒ–å®Œæˆ")
            
        except Exception as e:
            logger.warning(f"âš ï¸ MADDPGæ¨¡å‹åˆå§‹åŒ–å¤±è´¥: {e}")
            self.maddpg_model = None
    
    def _initialize_distributed_control(self):
        """åˆå§‹åŒ–åˆ†å¸ƒå¼æ§åˆ¶ç³»ç»Ÿ"""
        try:
            # å®šä¹‰æ§åˆ¶å™¨é…ç½®
            controller_configs = {
                'doctors': {
                    'feedback_gain': np.array([[0.5, 0.3, 0.2, 0.1],
                                              [0.3, 0.6, 0.1, 0.2],
                                              [0.2, 0.1, 0.5, 0.3],
                                              [0.1, 0.2, 0.3, 0.4]]),
                    'integrator_gain': 0.1,
                    'control_limits': [-1.0, 1.0]
                },
                'interns': {
                    'observer_gain': np.array([[0.4, 0.3, 0.2, 0.1],
                                              [0.3, 0.4, 0.1, 0.2],
                                              [0.2, 0.1, 0.4, 0.3],
                                              [0.1, 0.2, 0.3, 0.4]]),
                    'feedforward_gain': 0.2,
                    'control_limits': [-1.0, 1.0]
                },
                'patients': {
                    'Kp': 0.5,
                    'Ka': 0.2,
                    'control_limits': [-1.0, 1.0]
                },
                'accountants': {
                    'constraint_matrix': np.array([[0.6, 0.3, 0.1],
                                                  [0.3, 0.5, 0.2],
                                                  [0.1, 0.2, 0.7]]),
                    'budget_limit': 1.0,
                    'constraint_weights': np.array([0.6, 0.3, 0.1]),
                    'safety_margin': 0.1,
                    'control_limits': [-1.0, 1.0]
                },
                'government': {
                    'policy_matrix': np.array([[0.4, 0.3, 0.3],
                                              [0.3, 0.4, 0.3],
                                              [0.3, 0.3, 0.4]]),
                    'policy_limits': [-1.0, 1.0]
                }
            }
            
            # åˆ›å»ºåˆ†å¸ƒå¼æ§åˆ¶ç³»ç»Ÿ
            self.distributed_controller = DistributedControlSystem(controller_configs)
            
            logger.info("âœ… åˆ†å¸ƒå¼æ§åˆ¶ç³»ç»Ÿåˆå§‹åŒ–å®Œæˆ")
            
        except Exception as e:
            logger.warning(f"âš ï¸ åˆ†å¸ƒå¼æ§åˆ¶ç³»ç»Ÿåˆå§‹åŒ–å¤±è´¥: {e}")
            self.distributed_controller = None
    
    def set_data_callback(self, callback: Callable):
        """è®¾ç½®æ•°æ®æ¨é€å›è°ƒå‡½æ•°"""
        self.data_callback = callback
        logger.info("ğŸ“¡ æ•°æ®å›è°ƒå·²è®¾ç½®")
    
    def step(self, training: bool = False) -> Dict[str, Any]:
        """æ‰§è¡Œä¸€ä¸ªä»¿çœŸæ­¥éª¤"""
        if not self.is_running:
            self.is_running = True
        
        self.current_step += 1
        self.simulation_time += self.config.time_scale
        
        # åˆå§‹åŒ–æ­¥éª¤æ•°æ®
        step_data = {
            'step': self.current_step,
            'time': self.simulation_time,
            'system_state': self._convert_state_to_dict(),  # è½¬æ¢ä¸ºå­—å…¸æ ¼å¼ç”¨äºå…¼å®¹æ€§
            'observations': {},
            'actions': {},
            'rewards': {},
            'decisions': {},
            'metrics': {},
            'crises': [],
            'parliament_meeting': False
        }
        
        try:
            # 1. æ£€æŸ¥è®®ä¼šä¼šè®®å‘¨æœŸ
            if self.current_step % self.config.meeting_interval == 0 and self.current_step > 0:
                parliament_result = self._run_parliament_meeting()
                step_data['parliament_meeting'] = True
                step_data['parliament_result'] = parliament_result
                logger.info(f"ğŸ›ï¸ è®®ä¼šä¼šè®®åœ¨ç¬¬{self.current_step}æ­¥ä¸¾è¡Œ")

            # 2. æ¨¡æ‹Ÿç³»ç»ŸåŠ¨æ€å˜åŒ–
            self._simulate_system_dynamics()

            # 3. æ™ºèƒ½ä½“å†³ç­–å’Œè¡ŒåŠ¨
            agent_actions = self._simulate_agent_decisions()
            step_data['actions'] = agent_actions

            # 4. å¤„ç†å±æœºäº‹ä»¶
            if self.config.enable_crises:
                crises = self._handle_random_crises()
                step_data['crises'] = crises

            # 5. è®¡ç®—æ€§èƒ½æŒ‡æ ‡
            metrics = self._calculate_performance_metrics()
            step_data['metrics'] = metrics
            self.performance_history.append(metrics)

            # 6. æ›´æ–°æ™ºèƒ½ä½“æ”¶ç›Š
            self._update_agent_payoffs(step_data)
            
            # 7. æ”¶é›†ç»éªŒæ•°æ®ç”¨äºMADDPGè®­ç»ƒ
            if self.config.enable_learning:
                self._collect_experience(step_data)

            # 8. ä½¿ç”¨holy_codeæ¨¡å—å¤„ç†è§„åˆ™æ¿€æ´»
            if self.holy_code_manager:
                try:
                    decision_context = {
                        'decision_type': 'routine_operation',
                        'current_state': self._convert_state_to_dict(),
                        'step': self.current_step,
                        'agent_id': 'system'
                    }
                    
                    guidance = self.holy_code_manager.process_agent_decision_request(
                        'system', decision_context
                    )
                    
                    # å°†æŒ‡å¯¼ä¿¡æ¯å‘é€åˆ°WebSocket
                    if self.data_callback and guidance:
                        rule_msg = {
                            'type': 'holy_code_update',
                            'guidance': guidance,
                            'timestamp': time.time()
                        }
                        if asyncio.iscoroutinefunction(self.data_callback):
                            loop = asyncio.get_event_loop()
                            if loop.is_running():
                                asyncio.create_task(self.data_callback(rule_msg))
                            else:
                                asyncio.run(self.data_callback(rule_msg))
                        else:
                            self.data_callback(rule_msg)
                            
                except Exception as e:
                    logger.warning(f"âš ï¸ Holy codeå†³ç­–å¤„ç†å¤±è´¥: {e}")

        except Exception as e:
            logger.error(f"âŒ ä»¿çœŸæ­¥éª¤æ‰§è¡Œé”™è¯¯: {e}")
            import traceback
            traceback.print_exc()
        
        # æ¨é€æ•°æ®åˆ°å›è°ƒ
        if self.data_callback:
            try:
                if asyncio.iscoroutinefunction(self.data_callback):
                    # å¼‚æ­¥å›è°ƒ
                    try:
                        loop = asyncio.get_event_loop()
                        if loop.is_running():
                            asyncio.create_task(self.data_callback(step_data))
                        else:
                            asyncio.run(self.data_callback(step_data))
                    except RuntimeError:
                        # æ²¡æœ‰äº‹ä»¶å¾ªç¯ï¼ŒåŒæ­¥è°ƒç”¨
                        asyncio.run(self.data_callback(step_data))
                else:
                    # åŒæ­¥å›è°ƒ
                    self.data_callback(step_data)
            except Exception as e:
                logger.error(f"âŒ æ•°æ®å›è°ƒæ‰§è¡Œå¤±è´¥: {e}")
        
        return step_data
    
    def _run_parliament_meeting(self) -> Dict[str, Any]:
        """è¿è¡Œè®®ä¼šä¼šè®® - é›†æˆæ™ºèƒ½ä½“ææ¡ˆç”Ÿæˆ"""
        try:
            if self.holy_code_manager:
                # ä½¿ç”¨RoleAgentå¯¹è±¡ç”Ÿæˆææ¡ˆï¼ˆå¦‚æœå¯ç”¨ï¼‰
                proposals = {}
                for agent_id, agent_info in self.agents.items():
                    if agent_info['active']:
                        proposal = self._generate_agent_proposal_advanced(agent_id, agent_info)
                        proposals[agent_id] = proposal
                
                # ä½¿ç”¨holy_codeæ¨¡å—çš„è®®ä¼šä¼šè®®æµç¨‹
                parliament_result = self.holy_code_manager.run_weekly_parliament_meeting(
                    self.agents, 
                    self.system_state
                )
                
                # è®°å½•è®®ä¼šå†å²
                parliament_record = {
                    'step': self.current_step,
                    'parliament_result': parliament_result,
                    'proposals': proposals,
                    'timestamp': time.time()
                }
                self.parliament_history.append(parliament_record)
                
                # è·å–å…±è¯†æ°´å¹³
                consensus_level = getattr(parliament_result, 'consensus_level', 0.7)
                logger.info(f"ğŸ›ï¸ è®®ä¼šä¼šè®®å®Œæˆï¼Œè¾¾æˆå…±è¯†: {consensus_level:.2f}")
                logger.info(f"ğŸ“‹ æœ¬æ¬¡æ”¶åˆ° {len(proposals)} é¡¹ææ¡ˆ")
                return parliament_record
            else:
                # å›é€€åˆ°ç®€åŒ–ç‰ˆæœ¬
                return self._run_parliament_meeting_fallback()
                
        except Exception as e:
            logger.error(f"âŒ è®®ä¼šä¼šè®®æ‰§è¡Œå¤±è´¥: {e}")
            return {'error': str(e)}
    
    def _generate_agent_proposal_advanced(self, agent_id: str, agent_info: Dict) -> Dict[str, Any]:
        """ç”Ÿæˆæ™ºèƒ½ä½“ææ¡ˆ - é›†æˆRoleAgentå¯¹è±¡æ–¹æ³•"""
        try:
            # ä¼˜å…ˆä½¿ç”¨RoleAgentå¯¹è±¡ç”Ÿæˆææ¡ˆ
            if agent_id in self.agent_objects:
                role_agent = self.agent_objects[agent_id]
                
                # æ„å»ºææ¡ˆä¸Šä¸‹æ–‡
                proposal_context = {
                    'system_state': self._convert_state_to_dict(),
                    'current_step': self.current_step,
                    'agent_performance': agent_info['performance'],
                    'parliament_history': self.parliament_history[-3:] if self.parliament_history else []  # æœ€è¿‘3æ¬¡ä¼šè®®
                }
                
                # å¦‚æœRoleAgentæœ‰formulate_proposalæ–¹æ³•ï¼Œä½¿ç”¨å®ƒ
                if hasattr(role_agent, 'formulate_proposal'):
                    proposal = role_agent.formulate_proposal(proposal_context)
                    logger.info(f"âœ… {agent_id} ä½¿ç”¨RoleAgentç”Ÿæˆææ¡ˆ")
                    return proposal
                    
                # å¦åˆ™ä½¿ç”¨LLMç”Ÿæˆææ¡ˆ
                elif self.llm_action_generator:
                    llm_proposal = self.llm_action_generator.generate_proposal_sync(
                        agent_id, proposal_context
                    )
                    return {
                        'agent_id': agent_id,
                        'proposal_text': llm_proposal.get('proposal', 'ç»´æŒç°çŠ¶'),
                        'priority': llm_proposal.get('priority', 0.5),
                        'expected_benefit': llm_proposal.get('benefit', 0.5),
                        'implementation_cost': llm_proposal.get('cost', 0.3),
                        'reasoning': llm_proposal.get('reasoning', 'LLMç”Ÿæˆææ¡ˆ'),
                        'strategy_params': agent_info['strategy_params'].tolist()
                    }
            
            # å›é€€åˆ°æ¨¡æ¿ææ¡ˆ
            return self._generate_agent_proposal(agent_id, agent_info)
            
        except Exception as e:
            logger.warning(f"âš ï¸ {agent_id} é«˜çº§ææ¡ˆç”Ÿæˆå¤±è´¥ï¼Œä½¿ç”¨æ¨¡æ¿: {e}")
            return self._generate_agent_proposal(agent_id, agent_info)
    
    def _generate_agent_proposal(self, agent_id: str, agent_info: Dict) -> Dict[str, Any]:
        """ç”Ÿæˆæ™ºèƒ½ä½“ææ¡ˆ"""
        proposal_types = {
            'doctors': ['æé«˜åŒ»ç–—è´¨é‡æ ‡å‡†', 'å¢åŠ åŒ»ç”ŸåŸ¹è®­é¡¹ç›®', 'æ”¹å–„åŒ»æ‚£æ²Ÿé€š'],
            'interns': ['æ‰©å¤§å®ä¹ ç”ŸåŸ¹è®­è§„æ¨¡', 'æé«˜å®ä¹ æ´¥è´´', 'æ”¹å–„å¯¼å¸ˆåˆ¶åº¦'],
            'patients': ['ç¼©çŸ­ç­‰å¾…æ—¶é—´', 'æé«˜æœåŠ¡è´¨é‡', 'é™ä½åŒ»ç–—è´¹ç”¨'],
            'accountants': ['ä¼˜åŒ–æˆæœ¬ç»“æ„', 'æé«˜è´¢åŠ¡é€æ˜åº¦', 'æ”¹å–„é¢„ç®—ç®¡ç†'],
            'government': ['åŠ å¼ºç›‘ç®¡æªæ–½', 'æé«˜åˆè§„æ ‡å‡†', 'ä¿ƒè¿›å…¬å¹³ç«äº‰']
        }
        
        proposals = proposal_types.get(agent_id, ['ç»´æŒç°çŠ¶'])
        selected_proposal = np.random.choice(proposals)
        
        return {
            'agent_id': agent_id,
            'proposal_text': selected_proposal,
            'priority': np.random.uniform(0.5, 1.0),
            'expected_benefit': np.random.uniform(0.3, 0.8),
            'implementation_cost': np.random.uniform(0.1, 0.5),
            'strategy_params': agent_info['strategy_params'].tolist()
        }
    
    def _run_parliament_meeting_fallback(self) -> Dict[str, Any]:
        """å›é€€çš„ç®€åŒ–è®®ä¼šä¼šè®®æµç¨‹"""
        # æ”¶é›†æ™ºèƒ½ä½“ææ¡ˆ
        proposals = {}
        for agent_id, agent_info in self.agents.items():
            if agent_info['active']:
                proposal = self._generate_agent_proposal(agent_id, agent_info)
                proposals[agent_id] = proposal
        
        # ç®€åŒ–çš„å…±è¯†ç®—æ³•
        if proposals:
            total_priority = sum(p['priority'] for p in proposals.values())
            consensus_level = min(0.9, total_priority / len(proposals))
            best_proposal = max(proposals.values(), key=lambda x: x['priority'])
            main_decision = best_proposal['proposal_text']
        else:
            consensus_level = 0.5
            main_decision = 'ç»´æŒç°çŠ¶'
        
        return {
            'consensus_level': consensus_level,
            'main_decision': main_decision,
            'participating_agents': list(proposals.keys()),
            'proposals': proposals
        }
    
    def _update_holy_code_via_consensus(self, consensus_result: Dict) -> Dict[str, Any]:
        """é€šè¿‡holy_codeæ¨¡å—æ›´æ–°ç¥åœ£æ³•å…¸"""
        if self.holy_code_manager:
            # ä½¿ç”¨holy_codeæ¨¡å—çš„å†™å…¥å…±è¯†åŠŸèƒ½
            try:
                self.holy_code_manager.write_consensus(consensus_result)
                return {
                    'success': True,
                    'consensus_level': consensus_result.get('consensus_level', 0.5),
                    'operation': 'HOLY_CODE_UPDATE'
                }
            except Exception as e:
                logger.warning(f"âš ï¸ Holy codeæ›´æ–°å¤±è´¥: {e}")
                return {'success': False, 'error': str(e)}
        else:
            return {'success': False, 'error': 'HolyCodeManageræœªåˆå§‹åŒ–'}
    
    def _calculate_meeting_rewards(self, parliament_result: Dict) -> Dict[str, float]:
        """è®¡ç®—è®®ä¼šä¼šè®®çš„æ”¶ç›Š"""
        if self.holy_code_manager:
            try:
                # ä½¿ç”¨holy_codeæ¨¡å—çš„æ”¶ç›Šè®¡ç®—
                rewards = self.holy_code_manager.calculate_rewards(
                    parliament_result, 
                    self.agents, 
                    self.system_state
                )
                return rewards
            except Exception as e:
                logger.warning(f"âš ï¸ Holy codeæ”¶ç›Šè®¡ç®—å¤±è´¥ï¼Œä½¿ç”¨ç®€åŒ–ç‰ˆæœ¬: {e}")
        
        # å›é€€åˆ°ç®€åŒ–æ”¶ç›Šè®¡ç®—
        base_reward = parliament_result.get('consensus_level', 0.5) * 0.5
        rewards = {}
        for agent_id in self.agents.keys():
            if self.agents[agent_id]['active']:
                agent_reward = base_reward + np.random.normal(0, 0.1)
                rewards[agent_id] = np.clip(agent_reward, -0.5, 1.0)
        return rewards
    
    def _update_agent_networks(self, rewards: Dict[str, float]):
        """æ›´æ–°æ™ºèƒ½ä½“çš„actor-criticç½‘ç»œ - é›†æˆMADDPGè®­ç»ƒ"""
        # ä½¿ç”¨MADDPGæ¨¡å‹è¿›è¡ŒçœŸæ­£çš„ç½‘ç»œè®­ç»ƒ
        if self.maddpg_model and self.config.enable_learning and len(self.experience_buffer) >= self.batch_size:
            try:
                # ä»ç»éªŒç¼“å†²åŒºé‡‡æ ·æ‰¹æ¬¡æ•°æ®
                batch = self._sample_experience_batch()
                
                # è®­ç»ƒMADDPGæ¨¡å‹
                losses = self.maddpg_model.train(batch)
                
                # è®°å½•è®­ç»ƒæŸå¤±
                total_loss = sum(losses.values()) if losses else 0
                logger.info(f"ğŸ§  MADDPGè®­ç»ƒå®Œæˆï¼Œå¹³å‡æŸå¤±: {total_loss/len(losses) if losses else 0:.4f}")
                
            except Exception as e:
                logger.warning(f"âš ï¸ MADDPGè®­ç»ƒå¤±è´¥: {e}")
        
        # æ›´æ–°ä¼ ç»Ÿçš„æ™ºèƒ½ä½“çŠ¶æ€
        for agent_id, reward in rewards.items():
            if agent_id in self.agents:
                # æ›´æ–°æ”¶ç›Š
                self.agents[agent_id]['payoff'] += reward
                
                # å¦‚æœæ²¡æœ‰MADDPGï¼Œä½¿ç”¨ç®€åŒ–çš„ç­–ç•¥å‚æ•°è°ƒæ•´
                if not self.maddpg_model:
                    learning_rate = 0.01
                    param_update = np.random.normal(0, learning_rate, 3)
                    self.agents[agent_id]['strategy_params'] += param_update
                    self.agents[agent_id]['strategy_params'] = np.clip(
                        self.agents[agent_id]['strategy_params'], 0.0, 1.0
                    )
                
                # æ›´æ–°æ€§èƒ½æŒ‡æ ‡
                performance_change = reward * 0.1
                self.agents[agent_id]['performance'] += performance_change
                self.agents[agent_id]['performance'] = np.clip(
                    self.agents[agent_id]['performance'], 0.1, 1.0
                )
    
    def _collect_experience(self, step_data: Dict[str, Any]):
        """æ”¶é›†ç»éªŒæ•°æ®ç”¨äºMADDPGè®­ç»ƒ"""
        if not self.maddpg_model or not self.config.enable_learning:
            return
        
        try:
            # è·å–å½“å‰çŠ¶æ€
            if self.system_state:
                current_state = self.system_state.to_vector()
            else:
                current_state = np.array(list(self._legacy_system_state.values())[:16])
            
            # ä¸ºæ¯ä¸ªæœ‰è¡ŒåŠ¨çš„æ™ºèƒ½ä½“æ”¶é›†ç»éªŒ
            for agent_id, action_data in step_data.get('actions', {}).items():
                if agent_id in self.agents and 'last_action_vector' in self.agents[agent_id]:
                    
                    # æ„å»ºç»éªŒå…ƒç»„
                    experience = {
                        'role': agent_id,
                        'state': current_state.copy(),
                        'action': self.agents[agent_id]['last_action_vector'].copy(),
                        'reward': step_data.get('rewards', {}).get(agent_id, 0.0),
                        'next_state': current_state.copy(),  # ä¸‹ä¸€æ­¥ä¼šåœ¨ä¸‹æ¬¡æ›´æ–°
                        'done': False
                    }
                    
                    # æ·»åŠ åˆ°ç»éªŒç¼“å†²åŒº
                    self.experience_buffer.append(experience)
                    
                    # é™åˆ¶ç¼“å†²åŒºå¤§å°
                    if len(self.experience_buffer) > self.max_buffer_size:
                        self.experience_buffer.pop(0)
                    
                    # æ¸…é™¤ä¸´æ—¶å­˜å‚¨çš„è¡ŒåŠ¨å‘é‡
                    del self.agents[agent_id]['last_action_vector']
            
        except Exception as e:
            logger.warning(f"âš ï¸ ç»éªŒæ”¶é›†å¤±è´¥: {e}")
    
    def _sample_experience_batch(self) -> List[Dict]:
        """ä»ç»éªŒç¼“å†²åŒºé‡‡æ ·è®­ç»ƒæ‰¹æ¬¡"""
        import random
        
        if len(self.experience_buffer) < self.batch_size:
            return self.experience_buffer.copy()
        
        return random.sample(self.experience_buffer, self.batch_size)
    
    def get_maddpg_stats(self) -> Dict[str, Any]:
        """è·å–MADDPGè®­ç»ƒç»Ÿè®¡ä¿¡æ¯"""
        if not self.maddpg_model:
            return {'status': 'disabled'}
        
        return {
            'status': 'enabled',
            'experience_buffer_size': len(self.experience_buffer),
            'max_buffer_size': self.max_buffer_size,
            'batch_size': self.batch_size,
            'ready_for_training': len(self.experience_buffer) >= self.batch_size,
            'agent_action_dims': {
                'doctors': 4, 'interns': 4, 'patients': 3, 
                'accountants': 4, 'government': 4
            }
        }
    
    def save_maddpg_model(self, filepath: str):
        """ä¿å­˜MADDPGæ¨¡å‹"""
        if self.maddpg_model:
            try:
                self.maddpg_model.save_models(filepath)
                logger.info(f"âœ… MADDPGæ¨¡å‹å·²ä¿å­˜åˆ°: {filepath}")
            except Exception as e:
                logger.error(f"âŒ MADDPGæ¨¡å‹ä¿å­˜å¤±è´¥: {e}")
        else:
            logger.warning("âš ï¸ MADDPGæ¨¡å‹æœªåˆå§‹åŒ–ï¼Œæ— æ³•ä¿å­˜")
    
    def load_maddpg_model(self, filepath: str):
        """åŠ è½½MADDPGæ¨¡å‹"""
        if self.maddpg_model:
            try:
                self.maddpg_model.load_models(filepath)
                logger.info(f"âœ… MADDPGæ¨¡å‹å·²ä»{filepath}åŠ è½½")
            except Exception as e:
                logger.error(f"âŒ MADDPGæ¨¡å‹åŠ è½½å¤±è´¥: {e}")
        else:
            logger.warning("âš ï¸ MADDPGæ¨¡å‹æœªåˆå§‹åŒ–ï¼Œæ— æ³•åŠ è½½")
    
    def _simulate_system_dynamics(self):
        """æ¨¡æ‹Ÿç³»ç»ŸåŠ¨æ€å˜åŒ– - é›†æˆåˆ†å¸ƒå¼æ§åˆ¶ç³»ç»Ÿ"""
        try:
            # è·å–å½“å‰çŠ¶æ€å‘é‡
            current_state_vector = self.system_state.to_vector()
            
            # ä½¿ç”¨åˆ†å¸ƒå¼æ§åˆ¶å™¨ç”Ÿæˆæ§åˆ¶è¾“å…¥
            if self.distributed_controller and hasattr(self, 'holy_code_manager'):
                try:
                    # è®¾å®šå‚è€ƒçŠ¶æ€ï¼ˆç†æƒ³çŠ¶æ€ï¼‰
                    x_ref = np.array([0.8, 0.3, 0.8, 0.85, 0.75, 0.8, 0.7, 0.8, 
                                     0.85, 0.8, 0.9, 0.1, 0.8, 0.7, 0.8, 0.9])
                    
                    # æ‰°åŠ¨é¢„æµ‹ï¼ˆç®€åŒ–ç‰ˆæœ¬ï¼‰
                    d_hat = np.random.normal(0, 0.1, 6)
                    
                    # è·å–ç¥åœ£æ³•å…¸çŠ¶æ€
                    holy_code_state = {}
                    if self.holy_code_manager:
                        system_status = self.holy_code_manager.get_system_status()
                        holy_code_state = {
                            'ethical_constraints': {
                                'min_quality_control': 0.7,
                                'max_workload': 0.8,
                                'min_health_level': 0.6,
                                'min_equity_level': 0.5
                            },
                            'rule_library': system_status.get('rule_library', {}),
                            'consensus_level': system_status.get('consensus_level', 0.7)
                        }
                    
                    # ä½¿ç”¨åˆ†å¸ƒå¼æ§åˆ¶å™¨è®¡ç®—æ§åˆ¶è¾“å…¥
                    u_t = self.distributed_controller.compute_control(
                        current_state_vector, x_ref, d_hat, holy_code_state
                    )
                    
                    logger.debug(f"ğŸ›ï¸ ä½¿ç”¨åˆ†å¸ƒå¼æ§åˆ¶å™¨ç”Ÿæˆæ§åˆ¶è¾“å…¥")
                    
                except Exception as e:
                    logger.warning(f"âš ï¸ åˆ†å¸ƒå¼æ§åˆ¶å™¨å¤±è´¥ï¼Œä½¿ç”¨éšæœºæ§åˆ¶: {e}")
                    # å›é€€åˆ°éšæœºæ§åˆ¶è¾“å…¥
                    u_t = np.random.normal(0, 0.1, 17)
            else:
                # å›é€€åˆ°éšæœºæ§åˆ¶è¾“å…¥ï¼ˆ17ç»´ï¼‰
                u_t = np.random.normal(0, 0.1, 17)
            
            # ç”Ÿæˆéšæœºæ‰°åŠ¨ï¼ˆ6ç»´ï¼‰
            d_t = np.random.normal(0, 0.05, 6)
            
            # ä½¿ç”¨æ ¸å¿ƒç³»ç»ŸåŠ¨åŠ›å­¦
            next_state_vector = self.system_dynamics.state_transition(current_state_vector, u_t, d_t)
            
            # æ›´æ–°ç³»ç»ŸçŠ¶æ€
            self.system_state = SystemState.from_vector(next_state_vector)
            self.state_space.update_state(next_state_vector)
            
        except Exception as e:
            logger.warning(f"âš ï¸ ç³»ç»ŸåŠ¨åŠ›å­¦æ›´æ–°å¤±è´¥ï¼Œä½¿ç”¨ç®€åŒ–æ¨¡å¼: {e}")
            # å›é€€åˆ°ç®€åŒ–çš„éšæœºæ¸¸èµ°
            state_vector = self.system_state.to_vector()
            noise = np.random.normal(0, 0.01, len(state_vector))
            new_state_vector = np.clip(state_vector + noise, 0, 1)
            self.system_state = SystemState.from_vector(new_state_vector)
    
    def _simulate_agent_decisions(self) -> Dict[str, Any]:
        """æ¨¡æ‹Ÿæ™ºèƒ½ä½“å†³ç­– - é›†æˆRoleAgentå’ŒLLMç”Ÿæˆ"""
        actions = {}
        
        for agent_id, agent_info in self.agents.items():
            if agent_info['active'] and np.random.random() < 0.7:  # 70%æ¦‚ç‡æœ‰è¡ŒåŠ¨
                
                # ä¼˜å…ˆä½¿ç”¨RoleAgentå¯¹è±¡
                if agent_id in self.agent_objects:
                    try:
                        role_agent = self.agent_objects[agent_id]
                        
                        # æ„å»ºè§‚æµ‹ä¸Šä¸‹æ–‡
                        observation_context = {
                            'role': agent_id,
                            'system_state': self._convert_state_to_dict(),
                            'agent_performance': agent_info['performance'],
                            'current_step': self.current_step,
                            'system_matrices': self.system_matrices if hasattr(self, 'system_matrices') else None
                        }
                        
                        # ä½¿ç”¨RoleAgentçš„æ™ºèƒ½å†³ç­–
                        if self.llm_action_generator and self.config.enable_llm_integration:
                            # ä½¿ç”¨LLMç”Ÿæˆè¡ŒåŠ¨
                            # å‡†å¤‡è§‚æµ‹å‘é‡
                            if self.system_state:
                                observation = self.system_state.to_vector()
                            else:
                                observation = np.array(list(self._legacy_system_state.values())[:16])
                            
                            # å‡†å¤‡holy_codeçŠ¶æ€
                            holy_code_state = {}
                            if hasattr(self, 'holy_code_manager') and self.holy_code_manager:
                                system_status = self.holy_code_manager.get_system_status()
                                holy_code_state = {
                                    'rules': system_status.get('rule_library', {}),
                                    'consensus': system_status.get('consensus_level', 0.7),
                                    'active_rules': len(system_status.get('rule_library', {}))
                                }
                            
                            llm_action_vector = self.llm_action_generator.generate_action_sync(
                                agent_id, observation, holy_code_state, observation_context
                            )
                            
                            # å°†æ•°å€¼å‘é‡è½¬æ¢ä¸ºæè¿°æ€§è¡ŒåŠ¨
                            selected_action = self._convert_action_vector_to_description(agent_id, llm_action_vector)
                            reasoning = f'{agent_id}åŸºäºLLMæ•°å€¼ç­–ç•¥å†³ç­–'
                            confidence = np.mean(np.abs(llm_action_vector))
                        else:
                            # å°è¯•ä½¿ç”¨MADDPGç½‘ç»œç”Ÿæˆè¡ŒåŠ¨
                            if self.maddpg_model and self.config.enable_learning:
                                try:
                                    # è·å–ç³»ç»ŸçŠ¶æ€å‘é‡
                                    if self.system_state:
                                        state_vector = self.system_state.to_vector()
                                    else:
                                        state_vector = np.array(list(self._legacy_system_state.values())[:16])
                                    
                                    # ä½¿ç”¨Actorç½‘ç»œç”Ÿæˆè¡ŒåŠ¨
                                    observations = {agent_id: state_vector}
                                    actions_dict = self.maddpg_model.get_actions(observations, training=True)
                                    action_vector = actions_dict[agent_id]
                                    
                                    # å°†è¡ŒåŠ¨å‘é‡è½¬æ¢ä¸ºæè¿°
                                    selected_action = self._convert_action_vector_to_description(agent_id, action_vector)
                                    reasoning = f'{agent_id}åŸºäºActorç½‘ç»œå†³ç­–'
                                    confidence = np.tanh(np.linalg.norm(action_vector))  # è¡ŒåŠ¨å¼ºåº¦è½¬ç½®ä¿¡åº¦
                                    
                                    # å­˜å‚¨ç”¨äºè®­ç»ƒçš„è¡ŒåŠ¨å‘é‡
                                    agent_info['last_action_vector'] = action_vector
                                    
                                except Exception as e:
                                    logger.warning(f"âš ï¸ {agent_id} Actorç½‘ç»œå†³ç­–å¤±è´¥ï¼Œä½¿ç”¨æ•°å­¦ç­–ç•¥: {e}")
                                    # å›é€€åˆ°RoleAgentæ•°å­¦ç­–ç•¥
                                    sampled_action = role_agent.sample_action(self.system_state)
                                    selected_action = f"æ•°å­¦ç­–ç•¥è¡ŒåŠ¨_{np.random.randint(1,5)}"
                                    reasoning = f'{agent_id}åŸºäºæ•°å­¦ç­–ç•¥é€‰æ‹©: {selected_action}'
                                    confidence = 0.7
                            else:
                                # ä½¿ç”¨åˆ†å¸ƒå¼æ§åˆ¶å™¨ä½œä¸ºå›é€€
                                if self.distributed_controller:
                                    try:
                                        # è·å–å½“å‰çŠ¶æ€å’Œå‚è€ƒçŠ¶æ€
                                        current_state = self.system_state.to_vector() if self.system_state else np.array(list(self._legacy_system_state.values())[:16])
                                        x_ref = np.array([0.8, 0.3, 0.8, 0.85, 0.75, 0.8, 0.7, 0.8, 
                                                         0.85, 0.8, 0.9, 0.1, 0.8, 0.7, 0.8, 0.9])
                                        d_hat = np.random.normal(0, 0.1, 6)
                                        
                                        # è·å–ç¥åœ£æ³•å…¸çŠ¶æ€
                                        holy_code_state = {}
                                        if self.holy_code_manager:
                                            system_status = self.holy_code_manager.get_system_status()
                                            holy_code_state = {
                                                'ethical_constraints': {
                                                    'min_quality_control': 0.7,
                                                    'max_workload': 0.8,
                                                    'min_health_level': 0.6,
                                                    'min_equity_level': 0.5
                                                }
                                            }
                                        
                                        # ä½¿ç”¨åˆ†å¸ƒå¼æ§åˆ¶å™¨
                                        control_signal = self.distributed_controller.compute_control(
                                            current_state, x_ref, d_hat, holy_code_state
                                        )
                                        
                                        # æå–è¯¥æ™ºèƒ½ä½“çš„æ§åˆ¶ä¿¡å·éƒ¨åˆ†
                                        agent_control_ranges = {
                                            'doctors': control_signal[0:4],
                                            'interns': control_signal[4:8], 
                                            'patients': control_signal[8:11],
                                            'accountants': control_signal[11:14],
                                            'government': control_signal[14:17]
                                        }
                                        
                                        if agent_id in agent_control_ranges:
                                            action_vector = agent_control_ranges[agent_id]
                                            selected_action = self._convert_action_vector_to_description(agent_id, action_vector)
                                            reasoning = f'{agent_id}åŸºäºåˆ†å¸ƒå¼æ§åˆ¶å™¨å†³ç­–'
                                            confidence = np.tanh(np.linalg.norm(action_vector))
                                            
                                            # å­˜å‚¨ç”¨äºè®­ç»ƒçš„è¡ŒåŠ¨å‘é‡
                                            agent_info['last_action_vector'] = action_vector
                                        else:
                                            selected_action = f"æ§åˆ¶ç­–ç•¥è¡ŒåŠ¨_{np.random.randint(1,5)}"
                                            reasoning = f'{agent_id}åŸºäºæ§åˆ¶ç­–ç•¥é€‰æ‹©: {selected_action}'
                                            confidence = 0.7
                                            
                                    except Exception as e:
                                        logger.warning(f"âš ï¸ {agent_id} åˆ†å¸ƒå¼æ§åˆ¶å™¨å¤±è´¥ï¼Œä½¿ç”¨æ•°å­¦ç­–ç•¥: {e}")
                                        selected_action = f"æ•°å­¦ç­–ç•¥è¡ŒåŠ¨_{np.random.randint(1,5)}"
                                        reasoning = f'{agent_id}åŸºäºæ•°å­¦ç­–ç•¥é€‰æ‹©: {selected_action}'
                                        confidence = 0.7
                                else:
                                    # ä½¿ç”¨RoleAgentçš„æ•°å­¦ç­–ç•¥
                                    selected_action = f"æ•°å­¦ç­–ç•¥è¡ŒåŠ¨_{np.random.randint(1,5)}"
                                    reasoning = f'{agent_id}åŸºäºæ•°å­¦ç­–ç•¥é€‰æ‹©: {selected_action}'
                                    confidence = 0.7
                        
                        # æ›´æ–°æ™ºèƒ½ä½“çŠ¶æ€ï¼ˆæ³¨é‡Šæ‰ä¸å­˜åœ¨çš„æ–¹æ³•ï¼‰
                        # role_agent.update_performance(confidence)
                        
                    except Exception as e:
                        logger.warning(f"âš ï¸ RoleAgent {agent_id} å†³ç­–å¤±è´¥ï¼Œä½¿ç”¨æ¨¡æ¿: {e}")
                        selected_action, reasoning, confidence = self._generate_template_action(agent_id)
                
                else:
                    # å›é€€åˆ°ä¼ ç»ŸLLMç”Ÿæˆæˆ–æ¨¡æ¿
                    if self.llm_action_generator and self.config.enable_llm_integration:
                        try:
                            observation_context = {
                                'role': agent_id,
                                'system_state': self._convert_state_to_dict(),
                                'agent_performance': agent_info['performance'],
                                'current_step': self.current_step
                            }
                            
                            llm_action = self.llm_action_generator.generate_action_sync(
                                agent_id, observation_context
                            )
                            
                            selected_action = llm_action.get('action', 'ç»´æŒç°çŠ¶')
                            reasoning = llm_action.get('reasoning', f'{agent_id}åŸºäºLLMå†³ç­–')
                            confidence = llm_action.get('confidence', 0.8)
                            
                        except Exception as e:
                            logger.warning(f"âš ï¸ LLMç”Ÿæˆå¤±è´¥ï¼Œä½¿ç”¨æ¨¡æ¿: {e}")
                            selected_action, reasoning, confidence = self._generate_template_action(agent_id)
                    else:
                        selected_action, reasoning, confidence = self._generate_template_action(agent_id)
                
                actions[agent_id] = {
                    'action': selected_action,
                    'confidence': confidence,
                    'reasoning': reasoning,
                    'strategy_params': agent_info['strategy_params'].tolist(),
                    'agent_type': 'RoleAgent' if agent_id in self.agent_objects else 'Template'
                }
                
                # æ›´æ–°æ™ºèƒ½ä½“çŠ¶æ€
                agent_info['last_decision'] = selected_action
        
        return actions
    
    def _convert_action_vector_to_description(self, agent_id: str, action_vector: np.ndarray) -> str:
        """å°†æ•°å€¼è¡ŒåŠ¨å‘é‡è½¬æ¢ä¸ºæè¿°æ€§è¡ŒåŠ¨"""
        # åŸºäºè¡ŒåŠ¨å‘é‡çš„æ•°å€¼ç”Ÿæˆæè¿°
        if len(action_vector) == 0:
            return "ç»´æŒç°çŠ¶"
        
        # è®¡ç®—è¡ŒåŠ¨å¼ºåº¦
        action_magnitude = np.linalg.norm(action_vector)
        dominant_action_idx = np.argmax(np.abs(action_vector))
        
        # è§’è‰²ç‰¹å®šçš„è¡ŒåŠ¨æ˜ å°„
        action_mappings = {
            'doctors': [
                'æé«˜åŒ»ç–—è¯Šæ–­ç²¾åº¦', 'ä¼˜åŒ–æ²»ç–—æ–¹æ¡ˆ', 'åŠ å¼ºæ‚£è€…æ²Ÿé€š', 'æ”¹è¿›åŒ»ç–—æµç¨‹'
            ],
            'interns': [
                'å¢åŠ å­¦ä¹ æ—¶é—´', 'å¯»æ±‚å¯¼å¸ˆæŒ‡å¯¼', 'å‚ä¸ç—…ä¾‹è®¨è®º', 'æé«˜æŠ€èƒ½è®­ç»ƒ'
            ],
            'patients': [
                'æå‡ºæœåŠ¡æ”¹è¿›å»ºè®®', 'åé¦ˆæ²»ç–—ä½“éªŒ', 'è¦æ±‚ç¼©çŸ­ç­‰å¾…æ—¶é—´', 'å…³æ³¨åŒ»ç–—è´¨é‡'
            ],
            'accountants': [
                'ä¼˜åŒ–æˆæœ¬æ§åˆ¶', 'æ”¹å–„è´¢åŠ¡æµç¨‹', 'æé«˜é¢„ç®—ç²¾åº¦', 'åŠ å¼ºè´¢åŠ¡ç›‘ç®¡'
            ],
            'government': [
                'åˆ¶å®šæ–°æ”¿ç­–', 'åŠ å¼ºç›‘ç®¡æªæ–½', 'ä¿ƒè¿›åŒ»ç–—å…¬å¹³', 'æé«˜æœåŠ¡æ ‡å‡†'
            ]
        }
        
        actions = action_mappings.get(agent_id, ['ç»´æŒç°çŠ¶', 'è¯„ä¼°çŠ¶å†µ', 'åˆ¶å®šè®¡åˆ’', 'æ‰§è¡Œæ”¹è¿›'])
        base_action = actions[dominant_action_idx % len(actions)]
        
        # æ ¹æ®è¡ŒåŠ¨å¼ºåº¦æ·»åŠ ä¿®é¥°
        if action_magnitude > 0.7:
            return f"å¼ºåŠ›æ¨è¿›ï¼š{base_action}"
        elif action_magnitude > 0.4:
            return f"ç§¯ææ‰§è¡Œï¼š{base_action}"
        else:
            return f"è°¨æ…å®æ–½ï¼š{base_action}"
    
    def _generate_template_action(self, agent_id: str) -> Tuple[str, str, float]:
        """ç”Ÿæˆæ¨¡æ¿è¡ŒåŠ¨ï¼ˆå›é€€æ–¹æ¡ˆï¼‰"""
        action_templates = {
            'doctors': ['è¯Šæ–­æ‚£è€…', 'åˆ¶å®šæ²»ç–—æ–¹æ¡ˆ', 'ç´§æ€¥æ•‘æ²»', 'åŒ»ç–—ä¼šè¯Š', 'æŒ‡å¯¼å®ä¹ ç”Ÿ'],
            'interns': ['å­¦ä¹ æ–°æŠ€èƒ½', 'ååŠ©è¯Šç–—', 'å‚ä¸åŸ¹è®­', 'ä¸´åºŠå®è·µ', 'è¯·æ•™å¯¼å¸ˆ'],
            'patients': ['å°±åŒ»å’¨è¯¢', 'åé¦ˆæ„è§', 'å‚ä¸æ²»ç–—', 'åº·å¤è®­ç»ƒ', 'æŠ•è¯‰å»ºè®®'],
            'accountants': ['æˆæœ¬åˆ†æ', 'é¢„ç®—è§„åˆ’', 'è´¢åŠ¡å®¡è®¡', 'èµ„æºä¼˜åŒ–', 'ç»©æ•ˆè¯„ä¼°'],
            'government': ['æ”¿ç­–åˆ¶å®š', 'ç›‘ç®¡æ£€æŸ¥', 'èµ„æºåˆ†é…', 'ç»©æ•ˆè¯„ä¼°', 'åˆè§„å®¡æŸ¥']
        }
        
        possible_actions = action_templates.get(agent_id, ['ç»´æŒç°çŠ¶'])
        selected_action = np.random.choice(possible_actions)
        
        # è®¡ç®—å†³ç­–ç½®ä¿¡åº¦
        performance = self.agents[agent_id]['performance']
        confidence = performance * (0.7 + np.random.random() * 0.3)
        reasoning = f"{self.agents[agent_id]['name']}åŸºäºå½“å‰ç³»ç»ŸçŠ¶æ€å’Œä¸ªäººç­–ç•¥æ‰§è¡Œ{selected_action}"
        
        return selected_action, reasoning, confidence
    
    def _handle_random_crises(self) -> List[Dict[str, Any]]:
        """å¤„ç†éšæœºå±æœºäº‹ä»¶"""
        crises = []
        
        if np.random.random() < self.config.crisis_probability:
            crisis_types = ['pandemic', 'funding_cut', 'staff_shortage', 'equipment_failure', 'cyber_attack']
            crisis_type = np.random.choice(crisis_types)
            severity = np.random.uniform(0.2, 0.8)
            duration = np.random.randint(5, 20)  # æŒç»­5-20æ­¥
            
            crisis = {
                'type': crisis_type,
                'severity': severity,
                'duration': duration,
                'start_step': self.current_step,
                'description': f'{crisis_type}å±æœº (ä¸¥é‡ç¨‹åº¦: {severity:.2f})',
                'affected_metrics': self._get_crisis_affected_metrics(crisis_type)
            }
            
            self._apply_crisis_effects(crisis)
            self.crisis_history.append(crisis)
            crises.append(crisis)
            
            logger.info(f"ğŸš¨ å±æœºäº‹ä»¶: {crisis['description']}")
        
        return crises
    
    def _get_crisis_affected_metrics(self, crisis_type: str) -> List[str]:
        """è·å–å±æœºå½±å“çš„æŒ‡æ ‡"""
        crisis_effects = {
            'pandemic': ['medical_quality', 'patient_safety', 'resource_adequacy', 'staff_satisfaction'],
            'funding_cut': ['financial_health', 'resource_adequacy', 'education_quality', 'salary_satisfaction'],
            'staff_shortage': ['workload', 'staff_satisfaction', 'patient_satisfaction', 'medical_quality'],
            'equipment_failure': ['resource_utilization', 'medical_quality', 'cost_efficiency'],
            'cyber_attack': ['system_stability', 'patient_safety', 'regulatory_compliance']
        }
        return crisis_effects.get(crisis_type, ['overall_performance'])
    
    def _apply_crisis_effects(self, crisis: Dict[str, Any]):
        """åº”ç”¨å±æœºå½±å“"""
        crisis_type = crisis['type']
        severity = crisis['severity']
        affected_metrics = crisis['affected_metrics']
        
        if HAS_CORE_MATH and hasattr(self.system_state, 'to_vector'):
            # ä½¿ç”¨coreæ¨¡å—çš„SystemState
            current_vector = self.system_state.to_vector()
            
            # æ˜ å°„æ—§çš„æŒ‡æ ‡åç§°åˆ°æ–°çš„çŠ¶æ€å‘é‡ç´¢å¼•
            metric_mapping = {
                'medical_quality': [10],  # care_quality_index
                'patient_safety': [11],   # safety_incident_rate (åå‘)
                'resource_adequacy': [0], # medical_resource_utilization
                'staff_satisfaction': [5], # intern_satisfaction
                'patient_satisfaction': [8], # patient_satisfaction
                'medical_quality': [10],
                'resource_utilization': [0],
                'cost_efficiency': [12],  # operational_efficiency
                'system_stability': [14], # crisis_response_capability
                'regulatory_compliance': [15] # regulatory_compliance_score
            }
            
            for metric in affected_metrics:
                if metric in metric_mapping:
                    indices = metric_mapping[metric]
                    for idx in indices:
                        if metric in ['waiting_times', 'workload', 'safety_incident_rate']:
                            # åå‘æŒ‡æ ‡ï¼šå±æœºä¼šå¢åŠ è¿™äº›æŒ‡æ ‡
                            current_vector[idx] = min(current_vector[idx] + severity * 0.3, 1.0)
                        else:
                            # æ­£å‘æŒ‡æ ‡ï¼šå±æœºä¼šå‡å°‘è¿™äº›æŒ‡æ ‡
                            current_vector[idx] = max(current_vector[idx] - severity * 0.2, 0.1)
            
            # æ›´æ–°å±æœºå“åº”èƒ½åŠ›ï¼ˆè¡¨ç¤ºå½“å‰å±æœºä¸¥é‡ç¨‹åº¦ï¼‰
            current_vector[14] = max(0.1, current_vector[14] - severity * 0.4)
            
            # æ›´æ–°SystemState
            self.system_state = SystemState.from_vector(current_vector)
            
        else:
            # å›é€€åˆ°æ—§çš„å­—å…¸å¤„ç†æ–¹å¼
            state_dict = self._convert_state_to_dict()
            for metric in affected_metrics:
                if metric in state_dict:
                    if metric in ['waiting_times', 'workload']:
                        state_dict[metric] += severity * 0.3
                        state_dict[metric] = min(state_dict[metric], 1.0)
                    else:
                        state_dict[metric] -= severity * 0.2
                        state_dict[metric] = max(state_dict[metric], 0.1)
            
            state_dict['crisis_severity'] = max(
                state_dict.get('crisis_severity', 0), severity
            )
    
    def _calculate_performance_metrics(self) -> Dict[str, float]:
        """è®¡ç®—æ€§èƒ½æŒ‡æ ‡"""
        # è·å–å½“å‰çŠ¶æ€çš„å­—å…¸è¡¨ç¤º
        state_dict = self._convert_state_to_dict()
        
        # è®¡ç®—å„ä¸ªç»´åº¦çš„å¹³å‡è¡¨ç°
        medical_dimension = np.mean([
            state_dict.get('medical_quality', 0.5),
            state_dict.get('patient_safety', 0.5),
            state_dict.get('care_quality', 0.5)
        ])
        
        resource_dimension = np.mean([
            state_dict.get('resource_adequacy', 0.5),
            state_dict.get('resource_utilization', 0.5),
            state_dict.get('resource_access', 0.5)
        ])
        
        financial_dimension = np.mean([
            state_dict.get('financial_health', 0.5),
            state_dict.get('cost_efficiency', 0.5),
            state_dict.get('revenue_growth', 0.5)
        ])
        
        satisfaction_dimension = np.mean([
            state_dict.get('patient_satisfaction', 0.5),
            state_dict.get('staff_satisfaction', 0.5)
        ])
        
        # æ€»ä½“æ€§èƒ½æŒ‡æ ‡
        overall_performance = np.mean([
            medical_dimension,
            resource_dimension, 
            financial_dimension,
            satisfaction_dimension
        ])
        
        metrics = {
            'medical_dimension': medical_dimension,
            'resource_dimension': resource_dimension,
            'financial_dimension': financial_dimension,
            'satisfaction_dimension': satisfaction_dimension,
            'overall_performance': overall_performance,
            'system_stability': state_dict.get('system_stability', 0.5),
            'crisis_count': len(self.crisis_history),
            'active_crisis': state_dict.get('crisis_severity', 0.0) > 0.1,
            'parliament_meetings': len(self.parliament_history),
            'consensus_efficiency': np.mean([p.get('consensus', {}).get('consensus_level', 0.5) 
                                          for p in self.parliament_history[-5:]]) if self.parliament_history else 0.5
        }
        
        return metrics
    
    def _update_agent_payoffs(self, step_data: Dict[str, Any]):
        """æ›´æ–°æ™ºèƒ½ä½“æ”¶ç›Š"""
        performance_metrics = step_data.get('metrics', {})
        overall_performance = performance_metrics.get('overall_performance', 0.5)
        
        for agent_id, agent_info in self.agents.items():
            if agent_info['active']:
                # åŸºç¡€æ”¶ç›ŠåŸºäºç³»ç»Ÿæ•´ä½“è¡¨ç°
                base_payoff = overall_performance * 0.1
                
                # è§’è‰²ç‰¹å®šçš„æ”¶ç›Šè°ƒæ•´
                role_multiplier = {
                    'doctors': performance_metrics.get('medical_dimension', 0.5),
                    'interns': performance_metrics.get('medical_dimension', 0.5) * 0.8,
                    'patients': performance_metrics.get('satisfaction_dimension', 0.5),
                    'accountants': performance_metrics.get('financial_dimension', 0.5),
                    'government': performance_metrics.get('system_stability', 0.5)
                }
                
                role_bonus = role_multiplier.get(agent_id, 0.5) * 0.05
                
                # éšæœºå˜åŠ¨
                noise = np.random.normal(0, 0.02)
                
                total_payoff = base_payoff + role_bonus + noise
                agent_info['payoff'] += total_payoff
    
    async def run_async(self, steps: int = None, scenario_runner=None, training: bool = False):
        """å¼‚æ­¥è¿è¡Œä»¿çœŸ"""
        if steps is None:
            steps = self.config.max_steps
        
        self.is_running = True
        logger.info(f"ğŸš€ å¼€å§‹å¼‚æ­¥ä»¿çœŸè¿è¡Œ: {steps}æ­¥")
        
        try:
            for step in range(steps):
                # æ£€æŸ¥æš‚åœçŠ¶æ€
                while self.is_paused and self.is_running:
                    await asyncio.sleep(0.1)
                
                if not self.is_running:
                    break
                
                # åœºæ™¯äº‹ä»¶æ’å…¥
                if scenario_runner is not None:
                    try:
                        scenario_runner.check_and_insert_event(self.current_step)
                    except Exception as e:
                        logger.warning(f"âš ï¸ åœºæ™¯äº‹ä»¶æ’å…¥å¤±è´¥: {e}")
                
                # æ‰§è¡Œä»¿çœŸæ­¥
                step_data = self.step(training=training)
                
                # å¼‚æ­¥ç­‰å¾…
                await asyncio.sleep(2.0)  # 2ç§’é—´éš”
                
                # è¿›åº¦æ˜¾ç¤º
                if step % 50 == 0:
                    logger.info(f"ğŸ“Š å¼‚æ­¥è¿›åº¦: {step}/{steps}æ­¥, æ€§èƒ½: {step_data.get('metrics', {}).get('overall_performance', 0):.2f}")
        
        except Exception as e:
            logger.error(f"âŒ å¼‚æ­¥ä»¿çœŸè¿è¡Œé”™è¯¯: {e}")
        finally:
            self.is_running = False
            logger.info("âœ… å¼‚æ­¥ä»¿çœŸè¿è¡Œå®Œæˆ")
    
    def run(self, steps: int = 1000, scenario_runner=None, training: bool = False):
        """åŒæ­¥è¿è¡Œä»¿çœŸ"""
        self.is_running = True
        results = []
        
        logger.info(f"ğŸš€ å¼€å§‹åŒæ­¥ä»¿çœŸè¿è¡Œ: {steps}æ­¥")
        
        try:
            for step in range(steps):
                if not self.is_running:
                    break
                
                # åœºæ™¯äº‹ä»¶æ’å…¥
                if scenario_runner is not None:
                    try:
                        scenario_runner.check_and_insert_event(self.current_step)
                    except Exception as e:
                        logger.warning(f"âš ï¸ åœºæ™¯äº‹ä»¶æ’å…¥å¤±è´¥: {e}")
                
                # ä»¿çœŸæ­¥
                step_data = self.step(training=training)
                results.append(step_data)
                
                if step % 100 == 0:
                    logger.info(f"ğŸ“Š è¿›åº¦: {step}/{steps}æ­¥, æ€§èƒ½: {step_data.get('metrics', {}).get('overall_performance', 0):.2f}")
        
        except Exception as e:
            logger.error(f"âŒ åŒæ­¥ä»¿çœŸè¿è¡Œé”™è¯¯: {e}")
        finally:
            self.is_running = False
            logger.info("âœ… åŒæ­¥ä»¿çœŸè¿è¡Œå®Œæˆ")
        
        return results
    
    def pause(self):
        """æš‚åœä»¿çœŸ"""
        self.is_paused = True
        logger.info("â¸ï¸ ä»¿çœŸå·²æš‚åœ")
    
    def resume(self):
        """æ¢å¤ä»¿çœŸ"""
        self.is_paused = False
        logger.info("â–¶ï¸ ä»¿çœŸå·²æ¢å¤")
    
    def stop(self):
        """åœæ­¢ä»¿çœŸ"""
        self.is_running = False
        self.is_paused = False
        logger.info("â¹ï¸ ä»¿çœŸå·²åœæ­¢")
    
    def reset(self):
        """é‡ç½®ä»¿çœŸå™¨"""
        self.current_step = 0
        self.simulation_time = 0.0
        self.is_running = False
        self.is_paused = False
        
        # é‡ç½®ç³»ç»ŸçŠ¶æ€ - ä½¿ç”¨coreæ¨¡å—çš„SystemState
        if HAS_CORE_MATH:
            from ..core.kallipolis_mathematical_core import SystemState
            self.system_state = SystemState(
                medical_resource_utilization=0.7,
                patient_waiting_time=0.3,
                financial_indicator=0.8,
                ethical_compliance=0.85,
                education_training_quality=0.7,
                intern_satisfaction=0.7,
                professional_development=0.6,
                mentorship_effectiveness=0.8,
                patient_satisfaction=0.85,
                service_accessibility=0.8,
                care_quality_index=0.9,
                safety_incident_rate=0.05,
                operational_efficiency=0.75,
                staff_workload_balance=0.7,
                crisis_response_capability=0.8,
                regulatory_compliance_score=0.9
            )
        
        # é‡ç½®æ™ºèƒ½ä½“çŠ¶æ€
        for agent_id, agent_info in self.agents.items():
            agent_info.update({
                'performance': 0.7 + np.random.random() * 0.2,
                'payoff': 0.0,
                'strategy_params': np.random.uniform(0.3, 0.7, 3),
                'last_decision': None,
                'active': True
            })
        
        # æ¸…ç†å†å²è®°å½•
        self.performance_history.clear()
        self.crisis_history.clear()
        self.decision_history.clear()
        self.parliament_history.clear()
        
        logger.info("ğŸ”„ ä»¿çœŸå™¨å·²é‡ç½®")
    
    def get_simulation_report(self) -> Dict[str, Any]:
        """è·å–ä»¿çœŸæŠ¥å‘Š"""
        try:
            metrics = self._calculate_performance_metrics()
            
            return {
                'simulation_info': {
                    'current_step': self.current_step,
                    'simulation_time': self.simulation_time,
                    'total_decisions': len(self.decision_history),
                    'total_crises': len(self.crisis_history),
                    'parliament_meetings': len(self.parliament_history),
                    'is_running': self.is_running,
                    'is_paused': self.is_paused
                },
                'system_state': self._convert_state_to_dict(),
                'performance_metrics': metrics,
                'agent_status': {
                    agent_id: {
                        'name': info['name'],
                        'performance': info['performance'],
                        'payoff': info['payoff'],
                        'active': info['active'],
                        'last_decision': info['last_decision']
                    }
                    for agent_id, info in self.agents.items()
                },
                'recent_activity': {
                    'recent_crises': self.crisis_history[-3:] if self.crisis_history else [],
                    'recent_parliament': self.parliament_history[-1:] if self.parliament_history else [],
                    'performance_trend': self.performance_history[-10:] if self.performance_history else []
                },
                'learning_status': {
                    'maddpg_stats': self.get_maddpg_stats(),
                    'learning_enabled': self.config.enable_learning,
                    'llm_enabled': self.config.enable_llm_integration,
                    'agent_objects_count': len(self.agent_objects)
                }
            }
        except Exception as e:
            logger.error(f"âŒ ç”Ÿæˆä»¿çœŸæŠ¥å‘Šå¤±è´¥: {e}")
            return {
                'error': str(e),
                'current_step': self.current_step,
                'system_state': self.system_state
            }

# å¯¼å‡ºçš„ç±»å’Œå‡½æ•°
__all__ = ['KallipolisSimulator', 'SimulationConfig']