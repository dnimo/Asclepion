"""
é‡æ„åçš„agentsæ¨¡ç»„é›†æˆæµ‹è¯•

æµ‹è¯•é‡æ„åçš„å„ä¸ªç»„ä»¶ä¹‹é—´çš„åä½œå’Œä¸€è‡´æ€§
"""

import numpy as np
import sys
import os

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.append(os.path.join(os.path.dirname(__file__), '..'))

def test_agents_module_integration():
    """æµ‹è¯•agentsæ¨¡ç»„çš„æ•´ä½“é›†æˆ"""
    try:
        from src.hospital_governance.agents import (
            # è§’è‰²æ™ºèƒ½ä½“
            RoleAgent, RoleManager, DoctorAgent, InternAgent, PatientAgent, 
            AccountantAgent, GovernmentAgent, AgentConfig,
            
            # è¡Œä¸ºæ¨¡å‹
            BehaviorModelFactory, BehaviorModelManager, BehaviorType, BehaviorParameters,
            
            # å­¦ä¹ æ¨¡å‹
            MADDPGModel,
            
            # LLMé›†æˆ
            LLMActionGenerator, LLMConfig, MockLLMProvider,
            
            # äº¤äº’å¼•æ“
            KallipolisInteractionEngine, MultiAgentInteractionEngine, InteractionConfig
        )
        
        print("âœ… æˆåŠŸå¯¼å…¥é‡æ„åçš„æ‰€æœ‰agentsæ¨¡ç»„ç»„ä»¶")
        return True
        
    except ImportError as e:
        print(f"âŒ å¯¼å…¥å¤±è´¥: {e}")
        return False

def test_role_agents_functionality():
    """æµ‹è¯•è§’è‰²æ™ºèƒ½ä½“åŠŸèƒ½"""
    try:
        from src.hospital_governance.agents import RoleManager, DoctorAgent, AgentConfig
        
        # åˆ›å»ºè§’è‰²ç®¡ç†å™¨
        role_manager = RoleManager()
        
        # åˆ›å»ºåŒ»ç”Ÿæ™ºèƒ½ä½“é…ç½®
        doctor_config = AgentConfig(
            role='doctors',
            action_dim=4,
            observation_dim=8
        )
        
        # åˆ›å»ºåŒ»ç”Ÿæ™ºèƒ½ä½“
        doctor = DoctorAgent(doctor_config)
        role_manager.register_agent(doctor)
        
        # æµ‹è¯•è§‚å¯ŸåŠŸèƒ½
        environment = {
            'medical_quality': 0.8,
            'patient_safety': 0.9,
            'resource_adequacy': 0.7,
            'staff_satisfaction': 0.6
        }
        
        observation = doctor.observe(environment)
        print(f"âœ… è§’è‰²æ™ºèƒ½ä½“è§‚å¯ŸåŠŸèƒ½æ­£å¸¸: {observation.shape}")
        
        # æµ‹è¯•è¡ŒåŠ¨é€‰æ‹©
        action = doctor.select_action(observation, training=False)
        print(f"âœ… è§’è‰²æ™ºèƒ½ä½“è¡ŒåŠ¨é€‰æ‹©æ­£å¸¸: {action.shape}")
        
        return True
        
    except Exception as e:
        print(f"âŒ è§’è‰²æ™ºèƒ½ä½“æµ‹è¯•å¤±è´¥: {e}")
        return False

def test_behavior_models_integration():
    """æµ‹è¯•è¡Œä¸ºæ¨¡å‹é›†æˆ"""
    try:
        from src.hospital_governance.agents import (
            BehaviorModelFactory, BehaviorModelManager, BehaviorType, BehaviorParameters
        )
        
        # åˆ›å»ºè¡Œä¸ºæ¨¡å‹ç®¡ç†å™¨
        manager = BehaviorModelManager()
        manager.create_all_role_models()
        
        print(f"âœ… è¡Œä¸ºæ¨¡å‹ç®¡ç†å™¨åˆ›å»ºæˆåŠŸï¼ŒåŒ…å« {len(manager.models)} ä¸ªè§’è‰²æ¨¡å‹")
        
        # æµ‹è¯•è§’è‰²ç‰¹å®šæ¨¡å‹
        doctor_model = BehaviorModelFactory.create_role_specific_model('doctors')
        print(f"âœ… åŒ»ç”Ÿè¡Œä¸ºæ¨¡å‹åˆ›å»ºæˆåŠŸ: {doctor_model.behavior_type}")
        
        # æµ‹è¯•è¡ŒåŠ¨æ¦‚ç‡è®¡ç®—
        observation = np.random.uniform(0, 1, 8)
        available_actions = np.array([
            [0.5, 0.3, 0.7, 0.2],
            [0.8, 0.1, 0.4, 0.6],
            [0.2, 0.9, 0.3, 0.5]
        ])
        context = {'reward_weights': np.ones(4)}
        
        probabilities = doctor_model.compute_action_probabilities(
            observation, available_actions, context
        )
        print(f"âœ… è¡Œä¸ºæ¨¡å‹è¡ŒåŠ¨æ¦‚ç‡è®¡ç®—æ­£å¸¸: {probabilities}")
        
        return True
        
    except Exception as e:
        print(f"âŒ è¡Œä¸ºæ¨¡å‹é›†æˆæµ‹è¯•å¤±è´¥: {e}")
        return False

def test_llm_integration():
    """æµ‹è¯•LLMé›†æˆåŠŸèƒ½"""
    try:
        from src.hospital_governance.agents import LLMActionGenerator, LLMConfig, MockLLMProvider
        
        # åˆ›å»ºLLMé…ç½®å’Œç”Ÿæˆå™¨
        config = LLMConfig(model_name="mock", temperature=0.7)
        provider = MockLLMProvider(config)
        generator = LLMActionGenerator(config, provider)
        
        print("âœ… LLMç»„ä»¶åˆ›å»ºæˆåŠŸ")
        
        # æµ‹è¯•è¡ŒåŠ¨ç”Ÿæˆ
        observation = np.array([0.7, 0.8, 0.6, 0.9, 0.5, 0.7, 0.4, 0.8])
        holy_code_state = {'active_rules': []}
        context = {'context_type': 'normal', 'role': 'doctors'}
        
        action = generator.generate_action_sync('doctors', observation, holy_code_state, context)
        print(f"âœ… LLMè¡ŒåŠ¨ç”Ÿæˆæ­£å¸¸: {action}")
        
        # æµ‹è¯•ç»Ÿè®¡ä¿¡æ¯
        stats = generator.get_generation_stats()
        print(f"âœ… LLMç»Ÿè®¡ä¿¡æ¯: æˆåŠŸç‡ {stats['success_rate']:.2f}")
        
        return True
        
    except Exception as e:
        print(f"âŒ LLMé›†æˆæµ‹è¯•å¤±è´¥: {e}")
        return False

def test_multi_agent_coordinator():
    """æµ‹è¯•å¤šæ™ºèƒ½ä½“åè°ƒå™¨"""
    try:
        from src.hospital_governance.agents import (
            RoleManager, MultiAgentInteractionEngine, InteractionConfig,
            DoctorAgent, InternAgent, AgentConfig
        )
        
        # åˆ›å»ºè§’è‰²ç®¡ç†å™¨å’Œæ™ºèƒ½ä½“
        role_manager = RoleManager()
        
        doctor_config = AgentConfig(role='doctors', action_dim=4, observation_dim=8)
        intern_config = AgentConfig(role='interns', action_dim=3, observation_dim=8)
        
        doctor = DoctorAgent(doctor_config)
        intern = InternAgent(intern_config)
        
        role_manager.register_agent(doctor)
        role_manager.register_agent(intern)
        
        # åˆ›å»ºäº¤äº’é…ç½®å’Œå¼•æ“
        interaction_config = InteractionConfig(
            use_behavior_models=False,  # disabled - using MADDPG + LLM
            use_learning_models=False,
            use_llm_generation=False,
            conflict_resolution="negotiation"
        )
        
        coordinator = MultiAgentInteractionEngine(role_manager, interaction_config)
        print("âœ… å¤šæ™ºèƒ½ä½“åè°ƒå™¨åˆ›å»ºæˆåŠŸ")
        
        # æµ‹è¯•è¡ŒåŠ¨ç”Ÿæˆå’Œåè°ƒ
        system_state = np.random.uniform(0, 1, 16)
        context = {
            'environment': {
                'medical_quality': 0.8,
                'resource_adequacy': 0.6,
                'education_effectiveness': 0.7
            },
            'context_type': 'normal'
        }
        
        actions = coordinator.generate_actions(system_state, context, training=False)
        print(f"âœ… åè°ƒè¡ŒåŠ¨ç”ŸæˆæˆåŠŸ: {list(actions.keys())}")
        
        # æµ‹è¯•äº¤äº’æŒ‡æ ‡
        metrics = coordinator.get_interaction_metrics()
        print(f"âœ… äº¤äº’æŒ‡æ ‡è®¡ç®—æˆåŠŸ: åˆä½œå¾—åˆ† {metrics.get('average_cooperation_score', 0):.2f}")
        
        return True
        
    except Exception as e:
        print(f"âŒ å¤šæ™ºèƒ½ä½“åè°ƒå™¨æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False

def test_complete_workflow():
    """æµ‹è¯•å®Œæ•´å·¥ä½œæµç¨‹"""
    try:
        from src.hospital_governance.agents import (
            RoleManager, MultiAgentInteractionEngine, InteractionConfig,
            BehaviorModelFactory, LLMActionGenerator, LLMConfig,
            DoctorAgent, InternAgent, AccountantAgent, AgentConfig
        )
        
        print("ğŸ”„ å¼€å§‹å®Œæ•´å·¥ä½œæµç¨‹æµ‹è¯•...")
        
        # 1. åˆ›å»ºæ™ºèƒ½ä½“
        role_manager = RoleManager()
        
        configs = {
            'doctors': AgentConfig(role='doctors', action_dim=4, observation_dim=8),
            'interns': AgentConfig(role='interns', action_dim=3, observation_dim=8),
            'accountants': AgentConfig(role='accountants', action_dim=3, observation_dim=8)
        }
        
        agents = {
            'doctors': DoctorAgent(configs['doctors']),
            'interns': InternAgent(configs['interns']),
            'accountants': AccountantAgent(configs['accountants'])
        }
        
        for agent in agents.values():
            role_manager.register_agent(agent)
        
        print("  âœ… æ™ºèƒ½ä½“åˆ›å»ºå’Œæ³¨å†Œå®Œæˆ")
        
        # 2. é…ç½®è¡Œä¸ºæ¨¡å‹
        for role, agent in agents.items():
            behavior_model = BehaviorModelFactory.create_role_specific_model(role)
            if hasattr(agent, 'set_behavior_model'):
                agent.set_behavior_model(behavior_model)
        
        print("  âœ… è¡Œä¸ºæ¨¡å‹é›†æˆå®Œæˆ")
        
        # 3. åˆ›å»ºåè°ƒå¼•æ“
        interaction_config = InteractionConfig(
            use_behavior_models=False,  # disabled - using MADDPG + LLM
            use_learning_models=False,
            use_llm_generation=False,
            conflict_resolution="negotiation"
        )
        
        coordinator = MultiAgentInteractionEngine(role_manager, interaction_config)
        print("  âœ… åè°ƒå¼•æ“åˆ›å»ºå®Œæˆ")
        
        # 4. æ¨¡æ‹Ÿå¤šè½®äº¤äº’
        print("  ğŸ”„ å¼€å§‹å¤šè½®äº¤äº’æ¨¡æ‹Ÿ...")
        
        for round_num in range(3):
            # ç”Ÿæˆç³»ç»ŸçŠ¶æ€
            system_state = np.random.uniform(0.3, 0.9, 16)
            
            # æ„å»ºä¸Šä¸‹æ–‡
            context = {
                'environment': {
                    'medical_quality': system_state[0],
                    'resource_adequacy': system_state[1],
                    'financial_health': system_state[2],
                    'education_effectiveness': system_state[3]
                },
                'context_type': 'normal',
                'round': round_num
            }
            
            # ç”Ÿæˆåè°ƒè¡ŒåŠ¨
            actions = coordinator.generate_actions(system_state, context, training=False)
            
            print(f"    è½®æ¬¡ {round_num + 1}: ç”Ÿæˆ {len(actions)} ä¸ªè§’è‰²çš„åè°ƒè¡ŒåŠ¨")
        
        # 5. è·å–æœ€ç»ˆæŒ‡æ ‡
        metrics = coordinator.get_interaction_metrics()
        print(f"  âœ… å®Œæ•´å·¥ä½œæµç¨‹æµ‹è¯•æˆåŠŸ:")
        print(f"    - æ€»äº¤äº’æ¬¡æ•°: {metrics.get('total_interactions', 0)}")
        print(f"    - å¹³å‡åˆä½œå¾—åˆ†: {metrics.get('average_cooperation_score', 0):.3f}")
        print(f"    - å¹³å‡å†²çªæ•°é‡: {metrics.get('average_conflict_count', 0):.3f}")
        
        return True
        
    except Exception as e:
        print(f"âŒ å®Œæ•´å·¥ä½œæµç¨‹æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False

if __name__ == "__main__":
    print("=== é‡æ„åçš„agentsæ¨¡ç»„é›†æˆæµ‹è¯• ===\\n")
    
    tests = [
        ("æ¨¡ç»„å¯¼å…¥æµ‹è¯•", test_agents_module_integration),
        ("è§’è‰²æ™ºèƒ½ä½“åŠŸèƒ½æµ‹è¯•", test_role_agents_functionality),
        ("è¡Œä¸ºæ¨¡å‹é›†æˆæµ‹è¯•", test_behavior_models_integration),
        ("LLMé›†æˆæµ‹è¯•", test_llm_integration),
        ("å¤šæ™ºèƒ½ä½“åè°ƒå™¨æµ‹è¯•", test_multi_agent_coordinator),
        ("å®Œæ•´å·¥ä½œæµç¨‹æµ‹è¯•", test_complete_workflow)
    ]
    
    passed = 0
    total = len(tests)
    
    for test_name, test_func in tests:
        print(f"ğŸ§ª {test_name}...")
        if test_func():
            passed += 1
            print(f"   âœ… é€šè¿‡\\n")
        else:
            print(f"   âŒ å¤±è´¥\\n")
    
    print(f"=== æµ‹è¯•ç»“æœ ===")
    print(f"é€šè¿‡: {passed}/{total}")
    print(f"æˆåŠŸç‡: {passed/total*100:.1f}%")
    
    if passed == total:
        print("\\nğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼agentsæ¨¡ç»„é‡æ„æˆåŠŸã€‚")
        print("\\nä¸»è¦æ”¹è¿›:")
        print("- âœ… è§£å†³äº†å¾ªç¯å¯¼å…¥é—®é¢˜")
        print("- âœ… ç»Ÿä¸€äº†è§’è‰²å‘½åçº¦å®š")
        print("- âœ… é‡æ„äº†äº¤äº’å¼•æ“æ¶æ„")
        print("- âœ… å®Œå–„äº†LLMé›†æˆåŠŸèƒ½")
        print("- âœ… æ·»åŠ äº†å¤šæ™ºèƒ½ä½“åè°ƒæœºåˆ¶")
        print("- âœ… ä¿®å¤äº†æ¥å£ä¸ä¸€è‡´é—®é¢˜")
        print("- âœ… å¢å¼ºäº†é”™è¯¯å¤„ç†å’Œé™çº§ç­–ç•¥")
    else:
        print(f"\\nâš ï¸  {total-passed} ä¸ªæµ‹è¯•å¤±è´¥ï¼Œéœ€è¦è¿›ä¸€æ­¥è°ƒè¯•ã€‚")