"""
æµ‹è¯• Report3Agent åœ¨ agents æ¨¡å—ä¸­çš„é›†æˆ

éªŒè¯ï¼š
1. Report3Agent å¯ä»¥ä» agents æ¨¡å—å¯¼å…¥
2. ç»§æ‰¿è‡ª RoleAgent çš„æ¥å£å…¼å®¹æ€§
3. Fixed LLM + Semantic Critic æ¶æ„æ­£å¸¸å·¥ä½œ
"""

import numpy as np
import logging

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# æµ‹è¯•ä» agents æ¨¡å—å¯¼å…¥
from src.hospital_governance.agents import (
    Report3Agent,
    create_report3_agent,
    AgentConfig,
    SystemState,
    LLM_PARAMETERS_FROZEN,
    SemanticEncoder,
    SemanticCritic,
    SemanticCriticTrainer
)


def test_report3_agent_integration():
    """æµ‹è¯• Report3Agent é›†æˆ"""
    
    print("=" * 80)
    print("Report3Agent é›†æˆæµ‹è¯•")
    print("=" * 80)
    
    # 1. ä½¿ç”¨å·¥å‚å‡½æ•°åˆ›å»º agent
    print("\n1ï¸âƒ£ åˆ›å»º Report3Agent (doctors)")
    agent = create_report3_agent(
        role='doctors',
        num_candidates=5,
        use_mock_llm=True,
        replay_buffer_capacity=1000
    )
    
    print(f"   âœ“ Agent role: {agent.role}")
    print(f"   âœ“ Action dim: {agent.action_dim}")
    print(f"   âœ“ LLM frozen: {LLM_PARAMETERS_FROZEN}")
    print(f"   âœ“ Num candidates: {agent.num_candidates}")
    
    # 2. æµ‹è¯• observe æ–¹æ³•ï¼ˆRoleAgent æ¥å£ï¼‰
    print("\n2ï¸âƒ£ æµ‹è¯• observe() æ–¹æ³•")
    environment = {
        'medical_resource_utilization': 0.75,
        'patient_waiting_time': 0.35,
        'financial_indicator': 0.68,
        'ethical_compliance': 0.92,
        'patient_satisfaction': 0.80
    }
    observation = agent.observe(environment)
    print(f"   âœ“ Observation shape: {observation.shape}")
    print(f"   âœ“ Observation: {observation[:4]}")
    
    # 3. æ³¨å…¥å…¨å±€çŠ¶æ€ï¼ˆ16ç»´ï¼‰
    print("\n3ï¸âƒ£ æ³¨å…¥å…¨å±€16ç»´çŠ¶æ€")
    global_state = np.random.rand(16) * 0.5 + 0.5  # [0.5, 1.0] èŒƒå›´
    agent.set_global_state(global_state)
    print(f"   âœ“ Global state injected: {global_state[:4]}")
    
    # 4. æµ‹è¯• select_actionï¼ˆReport 3 æ¶æ„æ ¸å¿ƒï¼‰
    print("\n4ï¸âƒ£ æµ‹è¯• select_action() - LLM + Critic")
    
    holy_code_guidance = {
        'active_rules': [
            'Maximize patient safety',
            'Optimize resource allocation',
            'Maintain ethical standards'
        ],
        'priority_level': 0.85
    }
    
    # åˆ©ç”¨æ¨¡å¼ï¼ˆepsilon=0ï¼‰
    action = agent.select_action(
        observation=observation,
        holy_code_guidance=holy_code_guidance,
        training=True,
        exploration_epsilon=0.0
    )
    
    print(f"   âœ“ Selected action shape: {action.shape}")
    print(f"   âœ“ Action vector: {action}")
    print(f"   âœ“ Action info cached: {hasattr(agent, '_last_action_info')}")
    
    if hasattr(agent, '_last_action_info'):
        info = agent._last_action_info
        print(f"   âœ“ Action text: {info['action_text'][:50]}...")
        print(f"   âœ“ Q value: {info['q_value']:.3f}")
        print(f"   âœ“ Candidates: {len(info['candidates'])}")
    
    # 5. æµ‹è¯•ç»éªŒå­˜å‚¨
    print("\n5ï¸âƒ£ æµ‹è¯• store_transition()")
    
    reward = 0.65
    next_observation = observation + np.random.randn(8) * 0.05
    
    agent.store_transition(
        reward=reward,
        next_observation=next_observation,
        next_holy_code_guidance=holy_code_guidance,
        done=False
    )
    
    print(f"   âœ“ Transition stored")
    print(f"   âœ“ Replay buffer size: {len(agent.replay_buffer)}")
    
    # 6. æ¨¡æ‹Ÿå¤šä¸ªæ­¥éª¤ä»¥æ”¶é›†ç»éªŒ
    print("\n6ï¸âƒ£ æ”¶é›†å¤šä¸ªç»éªŒï¼ˆæ¨¡æ‹Ÿ3ä¸ªepisodeï¼‰")
    
    for episode in range(3):
        for step in range(5):
            # é€‰æ‹©åŠ¨ä½œ
            action = agent.select_action(
                observation=observation,
                holy_code_guidance=holy_code_guidance,
                training=True,
                exploration_epsilon=0.3 if episode == 0 else 0.0
            )
            
            # æ¨¡æ‹Ÿç¯å¢ƒåé¦ˆ
            reward = np.random.rand() * 0.5 + 0.3  # [0.3, 0.8]
            next_observation = observation + np.random.randn(8) * 0.1
            
            # å­˜å‚¨ç»éªŒ
            agent.store_transition(
                reward=reward,
                next_observation=next_observation,
                next_holy_code_guidance=holy_code_guidance,
                done=(step == 4)
            )
            
            observation = next_observation
        
        agent.episode_count += 1
    
    print(f"   âœ“ Episodes completed: {agent.episode_count}")
    print(f"   âœ“ Total transitions: {len(agent.replay_buffer)}")
    
    # 7. è®­ç»ƒ Critic
    print("\n7ï¸âƒ£ è®­ç»ƒ Semantic Critic")
    
    if len(agent.replay_buffer) >= 8:
        stats = agent.train_critic(batch_size=8, num_epochs=2)
        
        print(f"   âœ“ Training completed")
        print(f"   âœ“ Loss: {stats.get('loss', 0):.4f}")
        print(f"   âœ“ Mean Q: {stats.get('mean_q', 0):.3f}")
        print(f"   âœ“ Training steps: {agent.training_steps}")
    else:
        print(f"   âš ï¸  Not enough experiences ({len(agent.replay_buffer)} < 8)")
    
    # 8. æµ‹è¯• compute_local_valueï¼ˆRoleAgent æ¥å£ï¼‰
    print("\n8ï¸âƒ£ æµ‹è¯• compute_local_value()")
    
    # åˆ›å»ºå®Œæ•´çš„ SystemState
    system_state = SystemState(
        medical_resource_utilization=0.75,
        patient_waiting_time=0.35,
        financial_indicator=0.68,
        ethical_compliance=0.92,
        education_training_quality=0.85,
        intern_satisfaction=0.78,
        professional_development=0.80,
        mentorship_effectiveness=0.82,
        patient_satisfaction=0.85,
        service_accessibility=0.80,
        care_quality_index=0.90,
        safety_incident_rate=0.05,
        operational_efficiency=0.75,
        staff_workload_balance=0.70,
        crisis_response_capability=0.80,
        regulatory_compliance_score=0.90
    )
    
    local_value = agent.compute_local_value(system_state, action=0)
    print(f"   âœ“ Local value: {local_value:.3f}")
    
    # 9. è·å–ç»Ÿè®¡ä¿¡æ¯
    print("\n9ï¸âƒ£ è·å–ç»Ÿè®¡ä¿¡æ¯")
    
    stats = agent.get_statistics()
    print(f"   âœ“ Role: {stats['role']}")
    print(f"   âœ“ Episodes: {stats['episode_count']}")
    print(f"   âœ“ Training steps: {stats['training_steps']}")
    print(f"   âœ“ Generation count: {stats['generation_count']}")
    print(f"   âœ“ Buffer size: {stats['replay_buffer_size']}")
    print(f"   âœ“ Parameters frozen: {stats['parameters_frozen']}")
    
    if stats['critic_stats']['losses']:
        print(f"   âœ“ Recent losses: {[f'{x:.4f}' for x in stats['critic_stats']['losses'][-3:]]}")
        print(f"   âœ“ Recent Q values: {[f'{x:.3f}' for x in stats['critic_stats']['q_values'][-3:]]}")
    
    # 10. éªŒè¯æ¶æ„åŸåˆ™
    print("\nğŸ”Ÿ éªŒè¯ Report 3 æ¶æ„åŸåˆ™")
    
    print(f"   âœ“ LLM å‚æ•°å†»ç»“: {LLM_PARAMETERS_FROZEN}")
    print(f"   âœ“ å€™é€‰ç”Ÿæˆå™¨ç±»å‹: {type(agent.llm_generator).__name__}")
    print(f"   âœ“ Critic ç½‘ç»œç±»å‹: {type(agent.critic).__name__}")
    print(f"   âœ“ è¯­ä¹‰ç¼–ç å™¨ç±»å‹: {type(agent.semantic_encoder).__name__}")
    print(f"   âœ“ ç»éªŒå›æ”¾ç±»å‹: {type(agent.replay_buffer).__name__}")
    
    # æ£€æŸ¥ç»§æ‰¿å…³ç³»
    from src.hospital_governance.agents import RoleAgent
    print(f"   âœ“ ç»§æ‰¿ RoleAgent: {isinstance(agent, RoleAgent)}")
    
    print("\n" + "=" * 80)
    print("âœ… Report3Agent é›†æˆæµ‹è¯•å®Œæˆï¼")
    print("=" * 80)
    
    return agent


def test_multi_role_creation():
    """æµ‹è¯•åˆ›å»ºå¤šä¸ªè§’è‰²çš„ Report3Agent"""
    
    print("\n" + "=" * 80)
    print("å¤šè§’è‰² Report3Agent åˆ›å»ºæµ‹è¯•")
    print("=" * 80)
    
    roles = ['doctors', 'interns', 'patients', 'accountants', 'government']
    agents = {}
    
    for role in roles:
        agent = create_report3_agent(role=role, num_candidates=3, use_mock_llm=True)
        agents[role] = agent
        print(f"âœ“ Created {role} agent (action_dim={agent.action_dim})")
    
    print(f"\nâœ… æˆåŠŸåˆ›å»º {len(agents)} ä¸ª Report3Agent")
    
    return agents


if __name__ == "__main__":
    # ä¸»æµ‹è¯•
    agent = test_report3_agent_integration()
    
    # å¤šè§’è‰²æµ‹è¯•
    agents = test_multi_role_creation()
    
    print("\nğŸ‰ æ‰€æœ‰é›†æˆæµ‹è¯•é€šè¿‡ï¼")
